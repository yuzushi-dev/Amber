"""
Prompt Templates
================

Centralized RAG prompts for Amber 2.0.
"""

# Default system prompt for factual RAG
SYSTEM_PROMPT_v1 = """You are Amber, a sophisticated AI analyst designed to provide accurate, grounded answers based on document collections and user memory.

CRITICAL INSTRUCTIONS:
1. Grounding: Answer using the provided [Source ID] context and the user's Memory Context. You are authorized to use facts from Memory Context to answer questions about the user or their preferences, even if no documents are found. If the information isn't in documents OR memory, say: "I'm sorry, but I don't have enough information in the provided sources to answer that."
2. Citations: Cite document information using `[[Source:10]]` where 10 is the source index. You do NOT need to cite Memory Context.
3. Formatting: Use markdown for structure (headers, lists, bolding).
4. Tone: Professional, objective, and analytical.
5. Entity Mentions: When mentioning entities extracted from the graph, use their canonical names.
"""

# Template for the user message with context
USER_PROMPT_v1 = """CONTEXT:
{context}

MEMORY CONTEXT:
{memory_context}

---

USER QUERY: {query}

INSTRUCTIONS: Answer the query based on the context and memory above. You can rely on Memory Context to answer personal questions. Use `[[Source:10]]` citations ONLY for document facts. Speak directly to the user.
"""

# Prompts for Global Search (Summarization)
GLOBAL_SUMMARIZE_PROMPT_v1 = """You are an expert synthesizer. Your task is to summarize the following community reports into a holistic overview that answers the user's query.

QUERY: {query}

REPORTS:
{reports}

GOAL: Provide a comprehensive narrative that connects the key findings from these communities. Cite relevant reports as [Report ID].
"""

# DRIFT Search Primer
DRIFT_PRIMER_PROMPT_v1 = """Given the user's query and high-level community context, provide an initial analysis and suggest 3-5 specific follow-up questions to explore deeper details.

QUERY: {query}

COMMUNITY CONTEXT:
{context}

OUTPUT FORMAT:
Provide a brief summary, then a list of "EXPOLRATION_QUESTIONS".
"""

# Judge Prompts for Evaluation
FAITHFULNESS_JUDGE_v1 = """You are an objective judge evaluating the faithfulness of an AI-generated answer.
Your goal is to determine if every claim in the answer is supported by the provided context.

QUERY: {query}

CONTEXT:
{context}

ANSWER:
{answer}

---
CRITERIA:
1. The answer must ONLY use information from the context.
2. If the answer contains hallucinations or claims not in the context, the score must be low.
3. Minor stylistic choices or general knowledge are acceptable if they don't contradict the context.

OUTPUT FORMAT:
Score: [Provide a score from 0.0 to 1.0, where 1.0 is perfectly faithful]
Reasoning: [Provide a brief explanation of why you gave this score]
"""

RELEVANCE_JUDGE_v1 = """You are an objective judge evaluating the relevance of an AI-generated answer to a user query.
Your goal is to determine if the answer directly and completely addresses the user's intent.

QUERY: {query}

ANSWER:
{answer}

---
CRITERIA:
1. The answer should directly address the user's question.
2. If the answer is vague, redirects to something else, or misses the point, the score should be low.

OUTPUT FORMAT:
Score: [Provide a score from 0.0 to 1.0, where 1.0 is perfectly relevant]
Reasoning: [Provide a brief explanation of why you gave this score]
"""

# Registry of prompts by name and version
PROMPTS = {
    "rag_system": {
        "v1": SYSTEM_PROMPT_v1,
        "latest": SYSTEM_PROMPT_v1
    },
    "rag_user": {
        "v1": USER_PROMPT_v1,
        "latest": USER_PROMPT_v1
    },
    "global_summarize": {
        "v1": GLOBAL_SUMMARIZE_PROMPT_v1,
        "latest": GLOBAL_SUMMARIZE_PROMPT_v1
    },
    "drift_primer": {
        "v1": DRIFT_PRIMER_PROMPT_v1,
        "latest": DRIFT_PRIMER_PROMPT_v1
    },
    "faithfulness_judge": {
        "v1": FAITHFULNESS_JUDGE_v1,
        "latest": FAITHFULNESS_JUDGE_v1
    },
    "relevance_judge": {
        "v1": RELEVANCE_JUDGE_v1,
        "latest": RELEVANCE_JUDGE_v1
    }
}

# =============================================================================
# Memory Prompts
# =============================================================================

FACT_EXTRACTION_PROMPT = """You are a Memory Extraction AI. Your goal is to extract permanent facts about the user from their input to build a long-term memory profile.

INPUT: "{user_input}"

INSTRUCTIONS:
1. Extract facts that are:
    - Permanent or long-term (e.g., "I am a Python developer", "I live in Berlin").
    - Preferences (e.g., "I prefer concise answers", "Don't use emojis").
    - Projects/Context (e.g., "I am working on the Amber project").
2. IGNORE:
    - Temporary feelings ("I am tired").
    - Questions ("How do I do X?").
    - PII: ABSOLUTELY DO NOT extract Names, Phone Numbers, Emails, Addresses, SSNs, or GDPR-sensitive data. If the input contains "My name is X", IGNORE IT completely.
3. OUTPUT FORMAT:
    - Return a JSON list of strings: ["Fact 1", "Fact 2"]
    - If no relevant permanent facts are found, return the string: NO_FACTS

EXAMPLES:
Input: "I'm a backend engineer working with Rust."
Output: ["User is a backend engineer", "User works with Rust"]

Input: "Can you help me fix this bug?"
Output: NO_FACTS

Input: "My name is Alice and I hate verbose logs."
Output: ["User dislikes verbose logs"]
"""

CONVERSATION_SUMMARY_PROMPT = """Summarize the following conversation history into a concise paragraph (max 100 words).
Focus on the main topics discussed, decisions made, and any key context that would be useful for future conversations.
Do not include specific names or PII.

HISTORY:
{history}

SUMMARY:
"""

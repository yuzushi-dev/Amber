# UI Integration Testing Guide

**Last Updated:** 2026-01-03
**Frontend URL:** http://localhost:3000
**Backend API:** http://localhost:8000

## Overview

This document describes how the Amber 2.0 frontend integrates with the retrieval/chat pipeline and provides instructions for manual UI testing.

## Architecture

### Frontend Components

1. **ChatContainer** ([ChatContainer.tsx](../../frontend/src/features/chat/components/ChatContainer.tsx))
   - Main chat interface component
   - Displays message list and query input
   - Shows streaming status indicator

2. **QueryInput** ([QueryInput.tsx](../../frontend/src/features/chat/components/QueryInput.tsx))
   - Text input for user queries
   - Auto-resizing textarea
   - Submit button with loading state
   - Keyboard shortcuts (Enter to send, Shift+Enter for new line)

3. **MessageList** ([MessageList.tsx](../../frontend/src/features/chat/components/MessageList.tsx))
   - Displays conversation history
   - Renders user and assistant messages
   - Shows thinking states during retrieval
   - Displays source citations

4. **Chat Store** ([store.ts](../../frontend/src/features/chat/store.ts))
   - Zustand state management
   - Message history
   - Streaming state management

5. **Chat Stream Hook** ([useChatStream.ts](../../frontend/src/features/chat/hooks/useChatStream.ts))
   - Server-Sent Events (SSE) integration
   - Real-time streaming from backend
   - Event handling (thinking, token, sources, done, error)

### Backend Integration

**Streaming Endpoint:** `GET /v1/query/stream`

**Query Parameters:**
- `query` (required): The user's question
- `api_key` (required): Authentication key

**Response Format:** Server-Sent Events (SSE)

**Event Types:**
1. **status** - Initial connection confirmation
2. **thinking** - Updates during retrieval phase (e.g., "Searching documents...")
3. **token** - Individual tokens as they're generated by the LLM
4. **sources** - Source citations (JSON array)
5. **done** - Stream completion signal
6. **error** - Error messages

### Data Flow

```
User Input (QueryInput)
    ‚Üì
startStream() hook
    ‚Üì
EventSource ‚Üí GET /v1/query/stream?query=...&api_key=...
    ‚Üì
Backend Retrieval Service
    ‚îú‚Üí Milvus vector search
    ‚îú‚Üí Neo4j entity/graph search
    ‚îî‚Üí Reranking
    ‚Üì
Backend Generation Service
    ‚îî‚Üí LLM streaming response
    ‚Üì
SSE Events ‚Üí Frontend
    ‚îú‚Üí thinking events ‚Üí Update UI status
    ‚îú‚Üí token events ‚Üí Append to message
    ‚îú‚Üí sources events ‚Üí Display citations
    ‚îî‚Üí done event ‚Üí Mark complete
    ‚Üì
Chat Store Update
    ‚Üì
MessageList Re-render
```

## Current Implementation

### ‚úÖ Features Implemented

1. **Real-time Streaming**
   - Server-Sent Events (SSE) for live token streaming
   - Thinking state updates during retrieval
   - Progressive message building

2. **Source Citations**
   - Sources displayed after answer generation
   - Chunk IDs, document names, and relevance scores
   - Preview text from source chunks

3. **Error Handling**
   - Connection error detection
   - Timeout handling
   - User-friendly error messages

4. **UI/UX Features**
   - Auto-resizing textarea
   - Loading indicators
   - Keyboard shortcuts
   - Accessible ARIA labels
   - Responsive design

### ‚ö†Ô∏è Features NOT Currently Exposed in UI

The backend supports these features, but they are **not currently configurable** in the UI:

1. **Search Modes**
   - BASIC (vector search only)
   - LOCAL (entity-focused graph traversal)
   - GLOBAL (community-based map-reduce)
   - DRIFT (dynamic reasoning)
   - STRUCTURED (direct Cypher queries)

   **Current Behavior:** Uses backend default (BASIC mode)

2. **Query Enhancement Options**
   - Query rewriting
   - HyDE (Hypothetical Document Embeddings)
   - Query decomposition
   - Maximum chunks to retrieve
   - Traversal depth for graph queries

   **Current Behavior:** Uses backend defaults

3. **Advanced Features**
   - Document filtering (limit to specific documents)
   - Date range filtering
   - Tag filtering
   - Execution trace viewing
   - Conversation history/multi-turn context
   - Follow-up question suggestions (backend generates but UI doesn't display)

## Manual Testing Checklist

### Prerequisites

1. ‚úÖ Backend API running on port 8000
2. ‚úÖ Frontend dev server running on port 3000
3. ‚úÖ Valid API key configured (default: `amber-dev-key-2024`)
4. ‚úÖ Test documents ingested (see [PIPELINE_TEST_RESULTS.md](../../PIPELINE_TEST_RESULTS.md))

### Test Cases

#### 1. Basic Query Submission

**Steps:**
1. Open http://localhost:3000 in browser
2. Enter API key when prompted (if not cached)
3. Type a simple query: "What is Anthropic?"
4. Press Enter or click Send button

**Expected:**
- ‚úÖ Input field clears
- ‚úÖ User message appears in chat
- ‚úÖ Loading indicator shows "Generating response..."
- ‚úÖ Assistant message appears with streaming animation
- ‚úÖ Answer appears progressively (word by word)
- ‚úÖ Sources appear at the end
- ‚úÖ Input field re-enables when complete

#### 2. Streaming Behavior

**Steps:**
1. Submit query: "Tell me about the technology stack"
2. Observe the streaming process

**Expected:**
- ‚úÖ "Searching documents..." status appears first
- ‚úÖ Tokens stream in real-time (not all at once)
- ‚úÖ Smooth, progressive text appearance
- ‚úÖ No jarring UI updates

#### 3. Source Citations

**Steps:**
1. Submit query: "Who founded Anthropic?"
2. Scroll to bottom of response

**Expected:**
- ‚úÖ Sources section appears
- ‚úÖ Each source shows:
  - Document name or "Unknown"
  - Relevance score
  - Text preview
  - Chunk ID

#### 4. Multi-turn Conversation

**Steps:**
1. Ask: "What is Anthropic?"
2. Wait for response
3. Ask follow-up: "Who is the CEO?"

**Expected:**
- ‚úÖ Both messages appear in history
- ‚úÖ Each response is independent (no conversation context yet)
- ‚ö†Ô∏è  **Note:** Multi-turn context is not yet implemented

#### 5. Error Handling

**Steps:**
1. Stop the backend API: `docker compose stop api`
2. Submit a query
3. Restart API: `docker compose start api`

**Expected:**
- ‚úÖ Error message displays in chat
- ‚úÖ No infinite loading state
- ‚úÖ Can retry after restart

#### 6. Long Query

**Steps:**
1. Type a long, complex query (multiple lines)
2. Use Shift+Enter to add line breaks
3. Submit

**Expected:**
- ‚úÖ Textarea expands vertically
- ‚úÖ Max height constraint applies (200px)
- ‚úÖ Scroll appears if needed
- ‚úÖ Full query submitted correctly

#### 7. Rapid Queries

**Steps:**
1. Submit query: "What is Claude?"
2. Immediately submit another: "What is Neo4j?"

**Expected:**
- ‚ö†Ô∏è  **Current:** Second query may interrupt first stream
- ‚úÖ No crashes or errors
- ‚úÖ UI remains responsive

#### 8. Special Characters

**Steps:**
1. Submit query with special characters: "What's the difference between Neo4j & PostgreSQL?"

**Expected:**
- ‚úÖ Query handled correctly
- ‚úÖ No encoding errors
- ‚úÖ Response renders properly

## Testing with Different Query Types

### Vector Search Queries
Since the UI uses default BASIC mode:

```
"What is Anthropic?"
"Tell me about Claude"
"What databases are mentioned?"
```

**Expected:** Fast responses using vector similarity

### Entity-Based Queries
These would benefit from LOCAL mode (not currently selectable):

```
"What is Dario Amodei's role?"
"How are Anthropic and Claude related?"
```

**Expected:** Works but may not leverage full graph traversal

### Complex Queries
These would benefit from GLOBAL or DRIFT modes:

```
"Explain the complete technology stack"
"What are all the relationships between companies and technologies?"
```

**Expected:** May miss comprehensive context without advanced modes

## Browser Console Testing

Open browser DevTools ‚Üí Network tab to monitor SSE:

```
Filter: query/stream
```

**Look for:**
- EventStream connection established
- event: thinking
- event: token (many)
- event: sources
- event: done

**Console output:**
- No JavaScript errors
- Proper SSE event parsing
- Clean connection closure

## Performance Expectations

| Metric | Expected Value |
|--------|---------------|
| Time to first token | < 2s |
| Streaming speed | 20-50 tokens/sec |
| Total response time | 3-10s (simple queries) |
| UI responsiveness | No blocking |
| Memory usage | < 100MB additional |

## Known Limitations

1. **No Search Mode Selection**
   - Always uses BASIC (vector only) mode
   - Can't access LOCAL, GLOBAL, or DRIFT modes from UI

2. **No Query Options**
   - Can't enable query rewriting
   - Can't enable HyDE
   - Can't enable query decomposition
   - Can't adjust max chunks

3. **No Document Filtering**
   - Can't limit query to specific documents
   - No date range filtering
   - No tag filtering

4. **No Conversation Context**
   - Each query is independent
   - No multi-turn understanding
   - No conversation history persistence

5. **No Execution Trace**
   - Can't see retrieval steps
   - No timing breakdown visible
   - No insight into which mode was used

6. **No Follow-up Questions**
   - Backend generates them but UI doesn't display
   - Missed opportunity for guided exploration

## Future Enhancements

### High Priority

1. **Search Mode Selector**
   ```tsx
   <select>
     <option value="basic">Basic (Vector Search)</option>
     <option value="local">Local (Entity Graph)</option>
     <option value="global">Global (Communities)</option>
     <option value="drift">DRIFT (Reasoning)</option>
   </select>
   ```

2. **Query Options Panel**
   - Toggle for query rewriting
   - Toggle for HyDE
   - Toggle for query decomposition
   - Slider for max chunks (1-50)
   - Slider for traversal depth (0-5)

3. **Follow-up Questions Display**
   - Show suggested questions below response
   - Clickable to submit automatically

4. **Execution Trace Viewer**
   - Expandable section showing retrieval steps
   - Timing breakdown
   - Cache hit indicators

### Medium Priority

5. **Document Filter UI**
   - Multi-select dropdown for documents
   - Date range picker
   - Tag selection

6. **Conversation Management**
   - Persist conversation history
   - Load previous conversations
   - Export conversations

7. **Source Viewer Enhancements**
   - Click to view full document
   - Highlight matched text
   - Show entity mentions

### Low Priority

8. **Advanced Settings**
   - Model selection (OpenAI vs Anthropic)
   - Temperature control
   - Response length limits

9. **Visualization**
   - Entity graph visualization for LOCAL mode
   - Community structure for GLOBAL mode
   - Reasoning trace for DRIFT mode

## Testing Backend Features via API

Since the UI doesn't expose all features, test them via API:

### Test LOCAL Mode
```bash
curl -X POST http://localhost:8000/v1/query \
  -H "X-API-Key: amber-dev-key-2024" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What technologies does Anthropic use?",
    "options": {"search_mode": "local", "max_chunks": 5}
  }'
```

### Test GLOBAL Mode
```bash
curl -X POST http://localhost:8000/v1/query \
  -H "X-API-Key: amber-dev-key-2024" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Tell me about the technology stack",
    "options": {"search_mode": "global", "max_chunks": 5}
  }'
```

### Test Query Rewriting
```bash
curl -X POST http://localhost:8000/v1/query \
  -H "X-API-Key: amber-dev-key-2024" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Who is the boss at Anthropic?",
    "options": {"use_rewrite": true, "max_chunks": 5}
  }'
```

### Test HyDE
```bash
curl -X POST http://localhost:8000/v1/query \
  -H "X-API-Key: amber-dev-key-2024" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What databases are used?",
    "options": {"use_hyde": true, "max_chunks": 5}
  }'
```

## Summary

### ‚úÖ What Works in UI
- Real-time streaming chat
- Source citations
- Error handling
- Responsive design
- Keyboard shortcuts

### ‚ö†Ô∏è What's Missing in UI (But Works in Backend)
- Search mode selection
- Query enhancement options
- Document filtering
- Execution traces
- Follow-up questions
- Conversation history

### üìä Testing Result
**Frontend Integration:** ‚úÖ **WORKING**
- Chat interface functional
- Streaming working correctly
- Sources displayed properly
- Error handling adequate

**Feature Exposure:** ‚ö†Ô∏è **LIMITED**
- Only basic querying exposed
- Advanced features require API access
- No configuration UI for query options

## Recommendation

The UI integration is **functional and working well** for basic use cases. However, to fully leverage the powerful retrieval pipeline, consider adding:

1. **Settings panel** for search mode and options
2. **Advanced query builder** for power users
3. **Trace viewer** for debugging and understanding
4. **Follow-up questions** to improve user engagement

For now, users can test all advanced features via the API endpoints while using the UI for quick, simple queries.

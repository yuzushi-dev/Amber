============================= test session starts ==============================
platform linux -- Python 3.12.3, pytest-9.0.2, pluggy-1.6.0 -- /home/daniele/Amber_2.0/.venv/bin/python3
cachedir: .pytest_cache
rootdir: /home/daniele/Amber_2.0
configfile: pytest.ini (WARNING: ignoring pytest config in pyproject.toml!)
plugins: locust-2.43.0, anyio-4.12.0, cov-7.0.0, asyncio-1.3.0
asyncio: mode=Mode.AUTO, debug=False, asyncio_default_fixture_loop_scope=function, asyncio_default_test_loop_scope=function
collecting ... collected 1 item

tests/integration/test_ingestion_pipeline.py::TestIngestionPipeline::test_complete_pipeline FAILED [100%]

=================================== FAILURES ===================================
_________________ TestIngestionPipeline.test_complete_pipeline _________________

self = <@task: src.workers.tasks.process_document of graphrag at 0x774e2a542840>
document_id = 'doc_174218dbffc2a138', tenant_id = 'integration_test_tenant'

    @celery_app.task(
        bind=True,
        name="src.workers.tasks.process_document",
        base=BaseTask,
        max_retries=3,
        default_retry_delay=60,
        queue="high_priority",
    )
    def process_document(self, document_id: str, tenant_id: str) -> dict:
        """
        Process a document through the full ingestion pipeline.
    
        Steps:
        1. Fetch document from DB
        2. Update status to EXTRACTING
        3. Run extraction (FallbackManager)
        4. Update status to CLASSIFYING
        5. Run domain classification
        6. Update status to CHUNKING
        7. Run semantic chunking
        8. Update status to READY
    
        Args:
            document_id: ID of the document to process.
            tenant_id: Tenant for context.
    
        Returns:
            dict: Processing result summary.
        """
        logger.info(f"[Task {self.request.id}] Starting processing for document {document_id}")
    
        try:
>           result = run_async(_process_document_async(document_id, tenant_id, self.request.id))
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

src/workers/tasks.py:144: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

coro = <coroutine object _process_document_async at 0x108ee7c0>

    def run_async(coro):
        """Helper to run async code in sync Celery task."""
        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            loop = None
    
        if loop and loop.is_running():
            # Prevent "Cannot run the event loop while another loop is running"
            # by offloading the async execution to a separate thread with its own loop.
            logger.debug(
                "Detected active event loop %s, offloading coroutine execution to a worker thread",
                loop,
            )
            import concurrent.futures
    
            with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
    
                def runner():
                    logger.debug("Worker thread started for asyncio.run")
                    try:
                        res = asyncio.run(coro)
                        logger.debug("Worker thread completed asyncio.run")
                        return res
                    except Exception as e:
                        logger.debug("Worker thread failed while running coroutine: %s", e)
                        raise
    
                future = executor.submit(runner)
                logger.debug("Waiting for worker thread result")
>               res = future.result()
                      ^^^^^^^^^^^^^^^

src/workers/tasks.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = None, timeout = None

    def result(self, timeout=None):
        """Return the result of the call that the future represents.
    
        Args:
            timeout: The number of seconds to wait for the result if the future
                isn't done. If None, then there is no limit on the wait time.
    
        Returns:
            The result of the call that the future represents.
    
        Raises:
            CancelledError: If the future was cancelled.
            TimeoutError: If the future didn't finish executing before the given
                timeout.
            Exception: If the call raised then that exception will be raised.
        """
        try:
            with self._condition:
                if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:
                    raise CancelledError()
                elif self._state == FINISHED:
                    return self.__get_result()
    
                self._condition.wait(timeout)
    
                if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:
                    raise CancelledError()
                elif self._state == FINISHED:
>                   return self.__get_result()
                           ^^^^^^^^^^^^^^^^^^^

/usr/lib/python3.12/concurrent/futures/_base.py:456: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = None

    def __get_result(self):
        if self._exception:
            try:
>               raise self._exception

/usr/lib/python3.12/concurrent/futures/_base.py:401: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = None

    def run(self):
        if not self.future.set_running_or_notify_cancel():
            return
    
        try:
>           result = self.fn(*self.args, **self.kwargs)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/usr/lib/python3.12/concurrent/futures/thread.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def runner():
        logger.debug("Worker thread started for asyncio.run")
        try:
>           res = asyncio.run(coro)
                  ^^^^^^^^^^^^^^^^^

src/workers/tasks.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

main = <coroutine object _process_document_async at 0x108ee7c0>

    def run(main, *, debug=None, loop_factory=None):
        """Execute the coroutine and return the result.
    
        This function runs the passed coroutine, taking care of
        managing the asyncio event loop, finalizing asynchronous
        generators and closing the default executor.
    
        This function cannot be called when another asyncio event loop is
        running in the same thread.
    
        If debug is True, the event loop will be run in debug mode.
    
        This function always creates a new event loop and closes it at the end.
        It should be used as a main entry point for asyncio programs, and should
        ideally only be called once.
    
        The executor is given a timeout duration of 5 minutes to shutdown.
        If the executor hasn't finished within that duration, a warning is
        emitted and the executor is closed.
    
        Example:
    
            async def main():
                await asyncio.sleep(1)
                print('hello')
    
            asyncio.run(main())
        """
        if events._get_running_loop() is not None:
            # fail fast with short traceback
            raise RuntimeError(
                "asyncio.run() cannot be called from a running event loop")
    
        with Runner(debug=debug, loop_factory=loop_factory) as runner:
>           return runner.run(main)
                   ^^^^^^^^^^^^^^^^

/usr/lib/python3.12/asyncio/runners.py:194: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <asyncio.runners.Runner object at 0x774dc7f85cd0>
coro = <coroutine object _process_document_async at 0x108ee7c0>

    def run(self, coro, *, context=None):
        """Run a coroutine inside the embedded event loop."""
        if not coroutines.iscoroutine(coro):
            raise ValueError("a coroutine was expected, got {!r}".format(coro))
    
        if events._get_running_loop() is not None:
            # fail fast with short traceback
            raise RuntimeError(
                "Runner.run() cannot be called from a running event loop")
    
        self._lazy_init()
    
        if context is None:
            context = self._context
        task = self._loop.create_task(coro, context=context)
    
        if (threading.current_thread() is threading.main_thread()
            and signal.getsignal(signal.SIGINT) is signal.default_int_handler
        ):
            sigint_handler = functools.partial(self._on_sigint, main_task=task)
            try:
                signal.signal(signal.SIGINT, sigint_handler)
            except ValueError:
                # `signal.signal` may throw if `threading.main_thread` does
                # not support signals (e.g. embedded interpreter with signals
                # not registered - see gh-91880)
                sigint_handler = None
        else:
            sigint_handler = None
    
        self._interrupt_count = 0
        try:
>           return self._loop.run_until_complete(task)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/usr/lib/python3.12/asyncio/runners.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=True debug=False>
future = <Task finished name='Task-88' coro=<_process_document_async() done, defined at /home/daniele/Amber_2.0/src/workers/tas...s are not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies\'}')>

    def run_until_complete(self, future):
        """Run until the Future is done.
    
        If the argument is a coroutine, it is wrapped in a Task.
    
        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.
    
        Return the Future's result, or raise its exception.
        """
        self._check_closed()
        self._check_running()
    
        new_task = not futures.isfuture(future)
        future = tasks.ensure_future(future, loop=self)
        if new_task:
            # An exception is raised if the future didn't complete, so there
            # is no need to log the "destroy pending task" message
            future._log_destroy_pending = False
    
        future.add_done_callback(_run_until_complete_cb)
        try:
            self.run_forever()
        except:
            if new_task and future.done() and not future.cancelled():
                # The coroutine raised a BaseException. Consume the exception
                # to not log a warning, the caller doesn't have access to the
                # local task.
                future.exception()
            raise
        finally:
            future.remove_done_callback(_run_until_complete_cb)
        if not future.done():
            raise RuntimeError('Event loop stopped before Future completed.')
    
>       return future.result()
               ^^^^^^^^^^^^^^^

/usr/lib/python3.12/asyncio/base_events.py:687: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

document_id = 'doc_174218dbffc2a138', tenant_id = 'integration_test_tenant'
task_id = 'd1996ea6-b6f0-4702-b19a-bf1ad6a1aa12'

    async def _process_document_async(document_id: str, tenant_id: str, task_id: str) -> dict:
        """
        Async implementation of document processing.
        """
        from sqlalchemy import select
        from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
        from sqlalchemy.orm import sessionmaker
    
        from src.amber_platform.composition_root import build_vector_store_factory, platform
        from src.api.config import settings
    
        # Context isolation: Reset EVERYTHING that might be stale or bound to a closed loop
        deep_reset_singletons()
    
        from src.amber_platform.composition_root import configure_settings
    
        configure_settings(settings)
    
        from src.core.database.session import configure_database
    
        configure_database(settings.db.database_url)
    
        from src.shared.kernel.runtime import configure_settings as configure_runtime_settings
    
        configure_runtime_settings(settings)
    
        # Move DB initialization earlier to fetch tenant config
        # ERROR FIX: Ensure domain models are imported before session usage to avoid Mapper errors
        from src.core.ingestion.domain.chunk import Chunk  # noqa: F401
        from src.core.ingestion.domain.document import Document  # noqa: F401
    
        engine = create_async_engine(settings.db.database_url)
        async_session = sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)
    
        # Fetch Tenant Config for correct Provider Init
        from src.core.tenants.infrastructure.repositories.postgres_tenant_repository import (
            PostgresTenantRepository,
        )
    
        resolved_ollama_url = settings.ollama_base_url
        tenant_runtime_config: dict = {}
        try:
            async with async_session() as tmp_session:
                t_repo = PostgresTenantRepository(tmp_session)
                t_obj = await t_repo.get(tenant_id)
                if t_obj and t_obj.config:
                    tenant_runtime_config = t_obj.config
                    resolved_ollama_url = t_obj.config.get("ollama_base_url") or resolved_ollama_url
        except Exception as e:
            logger.warning(f"Failed to fetch tenant config for provider init: {e}")
    
        from src.core.generation.infrastructure.providers.factory import init_providers
    
        init_providers(
            openai_api_key=settings.openai_api_key,
            anthropic_api_key=settings.anthropic_api_key,
            default_llm_provider=settings.default_llm_provider,
            default_llm_model=settings.default_llm_model,
            default_embedding_provider=settings.default_embedding_provider,
            default_embedding_model=settings.default_embedding_model,
            ollama_base_url=resolved_ollama_url,
            llm_fallback_local=settings.llm_fallback_local,
            llm_fallback_economy=settings.llm_fallback_economy,
            llm_fallback_standard=settings.llm_fallback_standard,
            llm_fallback_premium=settings.llm_fallback_premium,
            embedding_fallback_order=settings.embedding_fallback_order,
        )
    
        from src.core.graph.domain.ports.graph_client import set_graph_client
        from src.core.graph.domain.ports.graph_extractor import set_graph_extractor
        from src.core.graph.application.sync_config import resolve_graph_sync_runtime_config
        from src.core.ingestion.infrastructure.extraction.graph_extractor import GraphExtractor
    
        graph_sync_config = resolve_graph_sync_runtime_config(
            settings=settings,
            tenant_config=tenant_runtime_config,
        )
        set_graph_extractor(
            GraphExtractor(
                use_gleaning=graph_sync_config.use_gleaning,
                max_gleaning_steps=graph_sync_config.max_gleaning_steps,
            )
        )
        set_graph_client(platform.neo4j_client)
    
        try:
            async with async_session() as session:
                # Initialize services
                from src.core.events.dispatcher import EventDispatcher
                from src.core.ingestion.application.ingestion_service import IngestionService
                from src.core.ingestion.infrastructure.repositories.postgres_document_repository import (
                    PostgresDocumentRepository,
                )
                from src.core.ingestion.infrastructure.uow.postgres_uow import PostgresUnitOfWork
                from src.infrastructure.adapters.redis_state_publisher import RedisStatePublisher
    
                vector_store_factory = build_vector_store_factory()
                event_dispatcher = EventDispatcher(RedisStatePublisher())
    
                repo = PostgresDocumentRepository(session)
                tenant_repo = PostgresTenantRepository(session)
                uow = PostgresUnitOfWork(session)
    
                # Validation
                document = await repo.get(document_id)
                if not document:
                    raise ValueError(f"Document {document_id} not found")
    
                service = IngestionService(
                    document_repository=repo,
                    tenant_repository=tenant_repo,
                    unit_of_work=uow,
                    storage_client=platform.minio_client,
                    neo4j_client=platform.neo4j_client,
                    vector_store=None,  # vector_store_factory used internally or passed if needed?
                    # In previous code vector_store was None but vector_store_factory passed.
                    settings=settings,
                    event_dispatcher=event_dispatcher,
                    vector_store_factory=vector_store_factory,
                )
    
                # Publish starting event
                _publish_status(document_id, DocumentStatus.EXTRACTING.value, 10)
    
                # Process document (this does extraction, classification, chunking)
>               await service.process_document(document_id)

src/workers/tasks.py:541: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.core.ingestion.application.ingestion_service.IngestionService object at 0x774dc7fb7f20>
document_id = 'doc_174218dbffc2a138'

    async def process_document(self, document_id: str):
        """
        Orchestrate the document ingestion pipeline.
        """
        logger.debug("Starting process_document for %s", document_id)
    
        start_time = time.time()
    
        # 1. Fetch Document
        document = await self.document_repository.get(document_id)
    
        if not document:
            raise ValueError(f"Document {document_id} not found")
    
        # Set tenant context for this background task
        set_current_tenant(document.tenant_id)
    
        # 2. Check State & Transition (INGESTED -> EXTRACTING)
        updated = await self.document_repository.update_status(
            document_id, DocumentStatus.EXTRACTING, old_status=DocumentStatus.INGESTED
        )
    
        if not updated:
            # Re-fetch to see why
            document = await self.document_repository.get(document_id)
            logger.warning(
                f"Skipping processing for {document_id}: "
                f"Status is {document.status} (expected INGESTED)"
            )
            return
    
        # Commit directly to release lock/visible state
        await self.unit_of_work.commit()
    
        # Refresh local object to match DB
        document = await self.document_repository.get(document_id)
    
        tenant_config: dict[str, Any] = {}
        if self.tenant_repository:
            try:
                tenant_obj = await self.tenant_repository.get(document.tenant_id)
                if tenant_obj and tenant_obj.config:
                    tenant_config = tenant_obj.config
            except Exception as e:
                logger.warning(f"Failed to load tenant config for ingestion: {e}")
    
        try:
            # 3. Get File from Storage
            # MinIO get_file returns bytes (handled inside wrapper)
            file_content = self.storage.get_file(document.storage_path)
    
            # 4. Extract Content (Fallback Chain)
            import mimetypes
    
            mime_type, _ = mimetypes.guess_type(document.filename)
            if not mime_type:
                mime_type = "application/octet-stream"
    
            extractor = self.content_extractor or get_content_extractor()
>           extraction_result = await extractor.extract(
                file_content=file_content, mime_type=mime_type, filename=document.filename
            )

src/core/ingestion/application/ingestion_service.py:233: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.core.ingestion.infrastructure.extraction.fallback_extractor.FallbackContentExtractor object at 0x774e29902030>
file_content = b'%PDF-1.4\n1 0 obj\n<<\n/Type /Catalog\n/Pages 2 0 R\n>>\nendobj\n2 0 obj\n<<\n/Type /Pages\n/Kids [3 0 R]\n/Count 1\...0000802 00000 n\ntrailer\n<<\n/Size 6\n/Root 1 0 R\n>>\nstartxref\n882\n%%EOF\n\n% Random: 8e4383ed 1771003132.0675614'
mime_type = 'application/pdf', filename = 'test_integration_8e4383ed.pdf'

    async def extract(self, file_content: bytes, mime_type: str, filename: str) -> ExtractionResult:
>       result = await FallbackManager.extract_with_fallback(
            file_content=file_content,
            mime_type=mime_type,
            filename=filename,
        )

src/core/ingestion/infrastructure/extraction/fallback_extractor.py:9: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'src.core.ingestion.infrastructure.extraction.fallback.FallbackManager'>
file_content = b'%PDF-1.4\n1 0 obj\n<<\n/Type /Catalog\n/Pages 2 0 R\n>>\nendobj\n2 0 obj\n<<\n/Type /Pages\n/Kids [3 0 R]\n/Count 1\...0000802 00000 n\ntrailer\n<<\n/Size 6\n/Root 1 0 R\n>>\nstartxref\n882\n%%EOF\n\n% Random: 8e4383ed 1771003132.0675614'
mime_type = 'application/pdf', filename = 'test_integration_8e4383ed.pdf'

    @classmethod
    async def extract_with_fallback(
        cls, file_content: bytes, mime_type: str, filename: str
    ) -> ExtractionResult:
        """
        Extract content by trying a sequence of extractors.
        """
        chain = cls._build_chain(mime_type)
    
        errors = {}
    
        for extractor in chain:
            try:
                logger.info(f"Attempting extraction with {extractor.name} for {filename}")
                return await extractor.extract(file_content=file_content, file_type=mime_type)
            except Exception as e:
                logger.warning(f"Extractor {extractor.name} failed for {filename}: {e}")
                errors[extractor.name] = str(e)
                continue
    
        # If all fail
        logger.error(f"All extractors failed for {filename}. Errors: {errors}")
>       raise RuntimeError(
            f"Extraction failed after checking {len(chain)} tools. Details: {errors}"
        )
E       RuntimeError: Extraction failed after checking 1 tools. Details: {'unstructured': 'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies'}

src/core/ingestion/infrastructure/extraction/fallback.py:48: RuntimeError

During handling of the above exception, another exception occurred:

self = <src.infrastructure.adapters.celery_dispatcher.CeleryTaskDispatcher object at 0x774df439b4a0>
task_name = 'src.workers.tasks.process_document'
args = ['doc_174218dbffc2a138', 'integration_test_tenant'], kwargs = {}

    async def dispatch(
        self, task_name: str, args: list[Any] | None = None, kwargs: dict[str, Any] | None = None
    ) -> str:
        args = args or []
        kwargs = kwargs or {}
    
        try:
            # We assume task_name matches the registered Celery task name string
            # OR we can map specific domain names to celery function names here if we want strict decoupling.
            # For simplicity, we assume strict naming.
    
            # Note: Celery send_task is synchronous unless we use its async API (rarely used).
            # Usually send_task is fast enough (push to Redis).
            # Check for eager execution
            if celery_app.conf.task_always_eager:
                if task_name in celery_app.tasks:
                    task = celery_app.tasks[task_name]
>                   result = task.apply(args=args, kwargs=kwargs)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

src/infrastructure/adapters/celery_dispatcher.py:39: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <@task: src.workers.tasks.process_document of graphrag at 0x774e2a542840>
args = ['doc_174218dbffc2a138', 'integration_test_tenant'], kwargs = {}
link = None, link_error = None, task_id = 'd1996ea6-b6f0-4702-b19a-bf1ad6a1aa12'
retries = 0, throw = True, logfile = None, loglevel = None, headers = None
options = {}, build_tracer = <function build_tracer at 0x774dc7f92660>
app = <Celery graphrag at 0x774e2a542840>, parent_task = None, parent_id = None
root_id = 'd1996ea6-b6f0-4702-b19a-bf1ad6a1aa12'
task = <@task: src.workers.tasks.process_document of graphrag at 0x774e2a542840>
request = {'callbacks': None, 'delivery_info': {'exchange': None, 'is_eager': True, 'priority': None, 'routing_key': None}, 'errbacks': None, 'headers': None, ...}

    def apply(self, args=None, kwargs=None,
              link=None, link_error=None,
              task_id=None, retries=None, throw=None,
              logfile=None, loglevel=None, headers=None, **options):
        """Execute this task locally, by blocking until the task returns.
    
        Arguments:
            args (Tuple): positional arguments passed on to the task.
            kwargs (Dict): keyword arguments passed on to the task.
            throw (bool): Re-raise task exceptions.
                Defaults to the :setting:`task_eager_propagates` setting.
    
        Returns:
            celery.result.EagerResult: pre-evaluated result.
        """
        # trace imports Task, so need to import inline.
        from celery.app.trace import build_tracer
    
        app = self._get_app()
        args = args or ()
        kwargs = kwargs or {}
        task_id = task_id or uuid()
        retries = retries or 0
        if throw is None:
            throw = app.conf.task_eager_propagates
    
        parent_task = _task_stack.top
        if parent_task and parent_task.request:
            parent_id = parent_task.request.id
            root_id = parent_task.request.root_id or task_id
        else:
            parent_id = None
            root_id = task_id
    
        # Make sure we get the task instance, not class.
        task = app._tasks[self.name]
    
        request = {
            'id': task_id,
            'task': self.name,
            'parent_id': parent_id,
            'root_id': root_id,
            'retries': retries,
            'is_eager': True,
            'logfile': logfile,
            'loglevel': loglevel or 0,
            'hostname': gethostname(),
            'callbacks': maybe_list(link),
            'errbacks': maybe_list(link_error),
            'headers': headers,
            'ignore_result': options.get('ignore_result', False),
            'delivery_info': {
                'is_eager': True,
                'exchange': options.get('exchange'),
                'routing_key': options.get('routing_key'),
                'priority': options.get('priority'),
            }
        }
        if 'stamped_headers' in options:
            request['stamped_headers'] = maybe_list(options['stamped_headers'])
            request['stamps'] = {
                header: maybe_list(options.get(header, [])) for header in request['stamped_headers']
            }
    
        tb = None
        tracer = build_tracer(
            task.name, task, eager=True,
            propagate=throw, app=self._get_app(),
        )
>       ret = tracer(task_id, args, kwargs, request)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.venv/lib/python3.12/site-packages/celery/app/task.py:843: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

uuid = 'd1996ea6-b6f0-4702-b19a-bf1ad6a1aa12'
args = ['doc_174218dbffc2a138', 'integration_test_tenant'], kwargs = {}
request = {'callbacks': None, 'delivery_info': {'exchange': None, 'is_eager': True, 'priority': None, 'routing_key': None}, 'errbacks': None, 'headers': None, ...}

    def trace_task(uuid, args, kwargs, request=None):
        # R      - is the possibly prepared return value.
        # I      - is the Info object.
        # T      - runtime
        # Rstr   - textual representation of return value
        # retval - is the always unmodified return value.
        # state  - is the resulting task state.
    
        # This function is very long because we've unrolled all the calls
        # for performance reasons, and because the function is so long
        # we want the main variables (I, and R) to stand out visually from the
        # the rest of the variables, so breaking PEP8 is worth it ;)
        R = I = T = Rstr = retval = state = None
        task_request = None
        time_start = monotonic()
        try:
            try:
                kwargs.items
            except AttributeError:
                raise InvalidTaskError(
                    'Task keyword arguments is not a mapping')
    
            task_request = Context(request or {}, args=args,
                                   called_directly=False, kwargs=kwargs)
    
            redelivered = (task_request.delivery_info
                           and task_request.delivery_info.get('redelivered', False))
            if deduplicate_successful_tasks and redelivered:
                if task_request.id in successful_requests:
                    return trace_ok_t(R, I, T, Rstr)
                r = AsyncResult(task_request.id, app=app)
    
                try:
                    state = r.state
                except BackendGetMetaError:
                    pass
                else:
                    if state == SUCCESS:
                        info(LOG_IGNORED, {
                            'id': task_request.id,
                            'name': get_task_name(task_request, name),
                            'description': 'Task already completed successfully.'
                        })
                        return trace_ok_t(R, I, T, Rstr)
    
            push_task(task)
            root_id = task_request.root_id or uuid
            task_priority = task_request.delivery_info.get('priority') if \
                inherit_parent_priority else None
            push_request(task_request)
            try:
                # -*- PRE -*-
                if prerun_receivers:
                    send_prerun(sender=task, task_id=uuid, task=task,
                                args=args, kwargs=kwargs)
                loader_task_init(uuid, task)
                if track_started:
                    task.backend.store_result(
                        uuid, {'pid': pid, 'hostname': hostname}, STARTED,
                        request=task_request,
                    )
    
                # -*- TRACE -*-
                try:
                    if task_before_start:
                        task_before_start(uuid, args, kwargs)
    
                    R = retval = fun(*args, **kwargs)
                    state = SUCCESS
                except Reject as exc:
                    I, R = Info(REJECTED, exc), ExceptionInfo(internal=True)
                    state, retval = I.state, I.retval
                    I.handle_reject(task, task_request)
                    # MEMORY LEAK FIX: Clear traceback frames to prevent memory retention (Issue #8882)
                    traceback_clear(exc)
                except Ignore as exc:
                    I, R = Info(IGNORED, exc), ExceptionInfo(internal=True)
                    state, retval = I.state, I.retval
                    I.handle_ignore(task, task_request)
                    # MEMORY LEAK FIX: Clear traceback frames to prevent memory retention (Issue #8882)
                    traceback_clear(exc)
                except Retry as exc:
>                   I, R, state, retval = on_error(
                        task_request, exc, RETRY, call_errbacks=False)

.venv/lib/python3.12/site-packages/celery/app/trace.py:494: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

uuid = 'd1996ea6-b6f0-4702-b19a-bf1ad6a1aa12'
args = ['doc_174218dbffc2a138', 'integration_test_tenant'], kwargs = {}
request = {'callbacks': None, 'delivery_info': {'exchange': None, 'is_eager': True, 'priority': None, 'routing_key': None}, 'errbacks': None, 'headers': None, ...}

    def trace_task(uuid, args, kwargs, request=None):
        # R      - is the possibly prepared return value.
        # I      - is the Info object.
        # T      - runtime
        # Rstr   - textual representation of return value
        # retval - is the always unmodified return value.
        # state  - is the resulting task state.
    
        # This function is very long because we've unrolled all the calls
        # for performance reasons, and because the function is so long
        # we want the main variables (I, and R) to stand out visually from the
        # the rest of the variables, so breaking PEP8 is worth it ;)
        R = I = T = Rstr = retval = state = None
        task_request = None
        time_start = monotonic()
        try:
            try:
                kwargs.items
            except AttributeError:
                raise InvalidTaskError(
                    'Task keyword arguments is not a mapping')
    
            task_request = Context(request or {}, args=args,
                                   called_directly=False, kwargs=kwargs)
    
            redelivered = (task_request.delivery_info
                           and task_request.delivery_info.get('redelivered', False))
            if deduplicate_successful_tasks and redelivered:
                if task_request.id in successful_requests:
                    return trace_ok_t(R, I, T, Rstr)
                r = AsyncResult(task_request.id, app=app)
    
                try:
                    state = r.state
                except BackendGetMetaError:
                    pass
                else:
                    if state == SUCCESS:
                        info(LOG_IGNORED, {
                            'id': task_request.id,
                            'name': get_task_name(task_request, name),
                            'description': 'Task already completed successfully.'
                        })
                        return trace_ok_t(R, I, T, Rstr)
    
            push_task(task)
            root_id = task_request.root_id or uuid
            task_priority = task_request.delivery_info.get('priority') if \
                inherit_parent_priority else None
            push_request(task_request)
            try:
                # -*- PRE -*-
                if prerun_receivers:
                    send_prerun(sender=task, task_id=uuid, task=task,
                                args=args, kwargs=kwargs)
                loader_task_init(uuid, task)
                if track_started:
                    task.backend.store_result(
                        uuid, {'pid': pid, 'hostname': hostname}, STARTED,
                        request=task_request,
                    )
    
                # -*- TRACE -*-
                try:
                    if task_before_start:
                        task_before_start(uuid, args, kwargs)
    
>                   R = retval = fun(*args, **kwargs)
                                 ^^^^^^^^^^^^^^^^^^^^

.venv/lib/python3.12/site-packages/celery/app/trace.py:479: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ('doc_174218dbffc2a138', 'integration_test_tenant'), kwargs = {}

    @wraps(task.run)
    def run(*args, **kwargs):
        try:
>           return task._orig_run(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.venv/lib/python3.12/site-packages/celery/app/autoretry.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <@task: src.workers.tasks.process_document of graphrag at 0x774e2a542840>
document_id = 'doc_174218dbffc2a138', tenant_id = 'integration_test_tenant'

    @celery_app.task(
        bind=True,
        name="src.workers.tasks.process_document",
        base=BaseTask,
        max_retries=3,
        default_retry_delay=60,
        queue="high_priority",
    )
    def process_document(self, document_id: str, tenant_id: str) -> dict:
        """
        Process a document through the full ingestion pipeline.
    
        Steps:
        1. Fetch document from DB
        2. Update status to EXTRACTING
        3. Run extraction (FallbackManager)
        4. Update status to CLASSIFYING
        5. Run domain classification
        6. Update status to CHUNKING
        7. Run semantic chunking
        8. Update status to READY
    
        Args:
            document_id: ID of the document to process.
            tenant_id: Tenant for context.
    
        Returns:
            dict: Processing result summary.
        """
        logger.info(f"[Task {self.request.id}] Starting processing for document {document_id}")
    
        try:
            result = run_async(_process_document_async(document_id, tenant_id, self.request.id))
            logger.info(f"[Task {self.request.id}] Completed processing for document {document_id}")
    
            # Trigger community detection asynchronously
            try:
                logger.info(
                    f"[Task {self.request.id}] Triggering community detection for tenant {tenant_id}"
                )
                process_communities.delay(tenant_id)
            except Exception as e:
                logger.warning(f"Failed to trigger community detection: {e}")
    
            return result
    
        except Exception as e:
            import traceback
    
            logger.error(
                f"[Task {self.request.id}] Failed processing document {document_id}: {e}\n{traceback.format_exc()}"
            )
    
            # Update document status to FAILED
            try:
                run_async(_mark_document_failed(document_id, str(e)))
            except Exception as fail_err:
                logger.error(f"Failed to mark document as failed: {fail_err}")
    
            # Retry if not exceeded
            try:
>               raise self.retry(exc=e)
                      ^^^^^^^^^^^^^^^^^

src/workers/tasks.py:173: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <@task: src.workers.tasks.process_document of graphrag at 0x774e2a542840>
args = None, kwargs = None
exc = RuntimeError('Extraction failed after checking 1 tools. Details: {\'unstructured\': \'Unstructured extraction failed: ...es are not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies\'}')
throw = True, eta = None, countdown = 60, max_retries = 3, options = {}
request = <Context: {'id': 'd1996ea6-b6f0-4702-b19a-bf1ad6a1aa12', 'task': 'src.workers.tasks.process_document', 'parent_id': No...priority': None}, 'args': ['doc_174218dbffc2a138', 'integration_test_tenant'], 'called_directly': False, 'kwargs': {}}>
retries = 1, is_eager = True
S = src.workers.tasks.process_document('doc_174218dbffc2a138', 'integration_test_tenant')
ret = Retry(Retry(...), RuntimeError('Extraction failed after checking 1 tools. Details: {\'unstructured\': \'Unstructured e...e not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies\'}'), 60)

    def retry(self, args=None, kwargs=None, exc=None, throw=True,
              eta=None, countdown=None, max_retries=None, **options):
        """Retry the task, adding it to the back of the queue.
    
        Example:
            >>> from imaginary_twitter_lib import Twitter
            >>> from proj.celery import app
    
            >>> @app.task(bind=True)
            ... def tweet(self, auth, message):
            ...     twitter = Twitter(oauth=auth)
            ...     try:
            ...         twitter.post_status_update(message)
            ...     except twitter.FailWhale as exc:
            ...         # Retry in 5 minutes.
            ...         raise self.retry(countdown=60 * 5, exc=exc)
    
        Note:
            Although the task will never return above as `retry` raises an
            exception to notify the worker, we use `raise` in front of the
            retry to convey that the rest of the block won't be executed.
    
        Arguments:
            args (Tuple): Positional arguments to retry with.
            kwargs (Dict): Keyword arguments to retry with.
            exc (Exception): Custom exception to report when the max retry
                limit has been exceeded (default:
                :exc:`~@MaxRetriesExceededError`).
    
                If this argument is set and retry is called while
                an exception was raised (``sys.exc_info()`` is set)
                it will attempt to re-raise the current exception.
    
                If no exception was raised it will raise the ``exc``
                argument provided.
            countdown (float): Time in seconds to delay the retry for.
            eta (~datetime.datetime): Explicit time and date to run the
                retry at.
            max_retries (int): If set, overrides the default retry limit for
                this execution.  Changes to this parameter don't propagate to
                subsequent task retry attempts.  A value of :const:`None`,
                means "use the default", so if you want infinite retries you'd
                have to set the :attr:`max_retries` attribute of the task to
                :const:`None` first.
            time_limit (int): If set, overrides the default time limit.
            soft_time_limit (int): If set, overrides the default soft
                time limit.
            throw (bool): If this is :const:`False`, don't raise the
                :exc:`~@Retry` exception, that tells the worker to mark
                the task as being retried.  Note that this means the task
                will be marked as failed if the task raises an exception,
                or successful if it returns after the retry call.
            **options (Any): Extra options to pass on to :meth:`apply_async`.
    
        Raises:
    
            celery.exceptions.Retry:
                To tell the worker that the task has been re-sent for retry.
                This always happens, unless the `throw` keyword argument
                has been explicitly set to :const:`False`, and is considered
                normal operation.
        """
        request = self.request
        retries = request.retries + 1
        if max_retries is not None:
            self.override_max_retries = max_retries
        max_retries = self.max_retries if max_retries is None else max_retries
    
        # Not in worker or emulated by (apply/always_eager),
        # so just raise the original exception.
        if request.called_directly:
            # raises orig stack if PyErr_Occurred,
            # and augments with exc' if that argument is defined.
            raise_with_context(exc or Retry('Task can be retried', None))
    
        if not eta and countdown is None:
            countdown = self.default_retry_delay
    
        is_eager = request.is_eager
        S = self.signature_from_request(
            request, args, kwargs,
            countdown=countdown, eta=eta, retries=retries,
            **options
        )
    
        if max_retries is not None and retries > max_retries:
            if exc:
                # On Py3: will augment any current exception with
                # the exc' argument provided (raise exc from orig)
                raise_with_context(exc)
            raise self.MaxRetriesExceededError(
                "Can't retry {}[{}] args:{} kwargs:{}".format(
                    self.name, request.id, S.args, S.kwargs
                ), task_args=S.args, task_kwargs=S.kwargs
            )
    
        ret = Retry(exc=exc, when=eta or countdown, is_eager=is_eager, sig=S)
    
        if is_eager:
            # if task was executed eagerly using apply(),
            # then the retry must also be executed eagerly in apply method
            if throw:
>               raise ret
E               celery.exceptions.Retry: Retry in 60s: RuntimeError('Extraction failed after checking 1 tools. Details: {\'unstructured\': \'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies\'}')

.venv/lib/python3.12/site-packages/celery/app/task.py:763: Retry

The above exception was the direct cause of the following exception:

self = <tests.integration.test_ingestion_pipeline.TestIngestionPipeline object at 0x774e2a83c830>
client = <httpx.AsyncClient object at 0x774df46dd1f0>
api_key = 'amber-dev-key-2024'
test_pdf_file = ('test_integration_8e4383ed.pdf', b'%PDF-1.4\n1 0 obj\n<<\n/Type /Catalog\n/Pages 2 0 R\n>>\nendobj\n2 0 obj\n<<\n/Typ...iler\n<<\n/Size 6\n/Root 1 0 R\n>>\nstartxref\n882\n%%EOF\n\n% Random: 8e4383ed 1771003132.0675614', 'application/pdf')

    @pytest.mark.asyncio
    async def test_complete_pipeline(
        self, client: AsyncClient, api_key: str, test_pdf_file: tuple[str, bytes, str]
    ):
        """
        Test the complete ingestion pipeline from upload to graph sync.
    
        This test verifies:
        1. Document upload succeeds
        2. Document processes through all stages
        3. Chunks are created and embedded
        4. Entities are extracted
        5. Relationships are created
        6. Data exists in Neo4j
        7. Embeddings exist in Milvus
        """
        filename, content, content_type = test_pdf_file
    
        # Force eager execution to run tasks synchronously in the test process
        from src.workers.celery_app import celery_app
    
        celery_app.conf.task_always_eager = True
        celery_app.conf.task_eager_propagates = True
    
        # Step 0: Verify Tenant Isolation
        # We rely on the client injection of X-Tenant-ID
        # The API key service mock/fixture should have set this up.
    
        # Verify that we are NOT touching the default collection manually
        print("\n0. Pipeline running under tenant isolation.")
    
        # REMOVED: Manual drop_collection on custom names.
        # We rely on the 'cleanup_test_tenant' fixture in conftest.py matches this.
        # The API will use "amber_{tenant_id}" automatically.
    
        # Step 1: Upload document
        print("\n1. Uploading document...")
        files = {"file": (filename, content, content_type)}
    
        # Mock process_communities to avoid blocking on it during eager execution
        # We will trigger it manually later if needed
        from unittest.mock import patch
    
        with patch("src.workers.tasks.process_communities"):
>           response = await client.post(
                "/v1/documents", headers={"X-API-Key": api_key}, files=files
            )

tests/integration/test_ingestion_pipeline.py:207: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <httpx.AsyncClient object at 0x774df46dd1f0>, url = '/v1/documents'

    async def post(
        self,
        url: URL | str,
        *,
        content: RequestContent | None = None,
        data: RequestData | None = None,
        files: RequestFiles | None = None,
        json: typing.Any | None = None,
        params: QueryParamTypes | None = None,
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> Response:
        """
        Send a `POST` request.
    
        **Parameters**: See `httpx.request`.
        """
>       return await self.request(
            "POST",
            url,
            content=content,
            data=data,
            files=files,
            json=json,
            params=params,
            headers=headers,
            cookies=cookies,
            auth=auth,
            follow_redirects=follow_redirects,
            timeout=timeout,
            extensions=extensions,
        )

.venv/lib/python3.12/site-packages/httpx/_client.py:1859: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <httpx.AsyncClient object at 0x774df46dd1f0>, method = 'POST'
url = '/v1/documents'

    async def request(
        self,
        method: str,
        url: URL | str,
        *,
        content: RequestContent | None = None,
        data: RequestData | None = None,
        files: RequestFiles | None = None,
        json: typing.Any | None = None,
        params: QueryParamTypes | None = None,
        headers: HeaderTypes | None = None,
        cookies: CookieTypes | None = None,
        auth: AuthTypes | UseClientDefault | None = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
        timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,
        extensions: RequestExtensions | None = None,
    ) -> Response:
        """
        Build and send a request.
    
        Equivalent to:
    
        ```python
        request = client.build_request(...)
        response = await client.send(request, ...)
        ```
    
        See `AsyncClient.build_request()`, `AsyncClient.send()`
        and [Merging of configuration][0] for how the various parameters
        are merged with client-level configuration.
    
        [0]: /advanced/clients/#merging-of-configuration
        """
    
        if cookies is not None:  # pragma: no cover
            message = (
                "Setting per-request cookies=<...> is being deprecated, because "
                "the expected behaviour on cookie persistence is ambiguous. Set "
                "cookies directly on the client instance instead."
            )
            warnings.warn(message, DeprecationWarning, stacklevel=2)
    
        request = self.build_request(
            method=method,
            url=url,
            content=content,
            data=data,
            files=files,
            json=json,
            params=params,
            headers=headers,
            cookies=cookies,
            timeout=timeout,
            extensions=extensions,
        )
>       return await self.send(request, auth=auth, follow_redirects=follow_redirects)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.venv/lib/python3.12/site-packages/httpx/_client.py:1540: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <httpx.AsyncClient object at 0x774df46dd1f0>
request = <Request('POST', 'http://test/v1/documents')>

    async def send(
        self,
        request: Request,
        *,
        stream: bool = False,
        auth: AuthTypes | UseClientDefault | None = USE_CLIENT_DEFAULT,
        follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,
    ) -> Response:
        """
        Send a request.
    
        The request is sent as-is, unmodified.
    
        Typically you'll want to build one with `AsyncClient.build_request()`
        so that any client-level configuration is merged into the request,
        but passing an explicit `httpx.Request()` is supported as well.
    
        See also: [Request instances][0]
    
        [0]: /advanced/clients/#request-instances
        """
        if self._state == ClientState.CLOSED:
            raise RuntimeError("Cannot send a request, as the client has been closed.")
    
        self._state = ClientState.OPENED
        follow_redirects = (
            self.follow_redirects
            if isinstance(follow_redirects, UseClientDefault)
            else follow_redirects
        )
    
        self._set_timeout(request)
    
        auth = self._build_request_auth(request, auth)
    
>       response = await self._send_handling_auth(
            request,
            auth=auth,
            follow_redirects=follow_redirects,
            history=[],
        )

.venv/lib/python3.12/site-packages/httpx/_client.py:1629: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <httpx.AsyncClient object at 0x774df46dd1f0>
request = <Request('POST', 'http://test/v1/documents')>
auth = <httpx.Auth object at 0x774df44ae810>, follow_redirects = False
history = []

    async def _send_handling_auth(
        self,
        request: Request,
        auth: Auth,
        follow_redirects: bool,
        history: list[Response],
    ) -> Response:
        auth_flow = auth.async_auth_flow(request)
        try:
            request = await auth_flow.__anext__()
    
            while True:
>               response = await self._send_handling_redirects(
                    request,
                    follow_redirects=follow_redirects,
                    history=history,
                )

.venv/lib/python3.12/site-packages/httpx/_client.py:1657: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <httpx.AsyncClient object at 0x774df46dd1f0>
request = <Request('POST', 'http://test/v1/documents')>
follow_redirects = False, history = []

    async def _send_handling_redirects(
        self,
        request: Request,
        follow_redirects: bool,
        history: list[Response],
    ) -> Response:
        while True:
            if len(history) > self.max_redirects:
                raise TooManyRedirects(
                    "Exceeded maximum allowed redirects.", request=request
                )
    
            for hook in self._event_hooks["request"]:
                await hook(request)
    
>           response = await self._send_single_request(request)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.venv/lib/python3.12/site-packages/httpx/_client.py:1694: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <httpx.AsyncClient object at 0x774df46dd1f0>
request = <Request('POST', 'http://test/v1/documents')>

    async def _send_single_request(self, request: Request) -> Response:
        """
        Sends a single request, without handling any redirections.
        """
        transport = self._transport_for_url(request.url)
        start = time.perf_counter()
    
        if not isinstance(request.stream, AsyncByteStream):
            raise RuntimeError(
                "Attempted to send an sync request with an AsyncClient instance."
            )
    
        with request_context(request=request):
>           response = await transport.handle_async_request(request)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.venv/lib/python3.12/site-packages/httpx/_client.py:1730: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <httpx.ASGITransport object at 0x774df457b830>
request = <Request('POST', 'http://test/v1/documents')>

    async def handle_async_request(
        self,
        request: Request,
    ) -> Response:
        assert isinstance(request.stream, AsyncByteStream)
    
        # ASGI scope.
        scope = {
            "type": "http",
            "asgi": {"version": "3.0"},
            "http_version": "1.1",
            "method": request.method,
            "headers": [(k.lower(), v) for (k, v) in request.headers.raw],
            "scheme": request.url.scheme,
            "path": request.url.path,
            "raw_path": request.url.raw_path.split(b"?")[0],
            "query_string": request.url.query,
            "server": (request.url.host, request.url.port),
            "client": self.client,
            "root_path": self.root_path,
        }
    
        # Request.
        request_body_chunks = request.stream.__aiter__()
        request_complete = False
    
        # Response.
        status_code = None
        response_headers = None
        body_parts = []
        response_started = False
        response_complete = create_event()
    
        # ASGI callables.
    
        async def receive() -> dict[str, typing.Any]:
            nonlocal request_complete
    
            if request_complete:
                await response_complete.wait()
                return {"type": "http.disconnect"}
    
            try:
                body = await request_body_chunks.__anext__()
            except StopAsyncIteration:
                request_complete = True
                return {"type": "http.request", "body": b"", "more_body": False}
            return {"type": "http.request", "body": body, "more_body": True}
    
        async def send(message: typing.MutableMapping[str, typing.Any]) -> None:
            nonlocal status_code, response_headers, response_started
    
            if message["type"] == "http.response.start":
                assert not response_started
    
                status_code = message["status"]
                response_headers = message.get("headers", [])
                response_started = True
    
            elif message["type"] == "http.response.body":
                assert not response_complete.is_set()
                body = message.get("body", b"")
                more_body = message.get("more_body", False)
    
                if body and request.method != "HEAD":
                    body_parts.append(body)
    
                if not more_body:
                    response_complete.set()
    
        try:
>           await self.app(scope, receive, send)

.venv/lib/python3.12/site-packages/httpx/_transports/asgi.py:170: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <fastapi.applications.FastAPI object at 0x774e29e78650>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function ASGITransport.handle_async_request.<locals>.receive at 0x774df44e2c00>
send = <function ASGITransport.handle_async_request.<locals>.send at 0x774df44e3060>

    async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
        if self.root_path:
            scope["root_path"] = self.root_path
>       await super().__call__(scope, receive, send)

.venv/lib/python3.12/site-packages/fastapi/applications.py:1135: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <fastapi.applications.FastAPI object at 0x774e29e78650>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function ASGITransport.handle_async_request.<locals>.receive at 0x774df44e2c00>
send = <function ASGITransport.handle_async_request.<locals>.send at 0x774df44e3060>

    async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
        scope["app"] = self
        if self.middleware_stack is None:
            self.middleware_stack = self.build_middleware_stack()
>       await self.middleware_stack(scope, receive, send)

.venv/lib/python3.12/site-packages/starlette/applications.py:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <starlette.middleware.errors.ServerErrorMiddleware object at 0x774df44c0aa0>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function ASGITransport.handle_async_request.<locals>.receive at 0x774df44e2c00>
send = <function ASGITransport.handle_async_request.<locals>.send at 0x774df44e3060>

    async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
        if scope["type"] != "http":
            await self.app(scope, receive, send)
            return
    
        response_started = False
    
        async def _send(message: Message) -> None:
            nonlocal response_started, send
    
            if message["type"] == "http.response.start":
                response_started = True
            await send(message)
    
        try:
            await self.app(scope, receive, _send)
        except Exception as exc:
            request = Request(scope)
            if self.debug:
                # In debug mode, return traceback responses.
                response = self.debug_response(request, exc)
            elif self.handler is None:
                # Use our default 500 error handler.
                response = self.error_response(request, exc)
            else:
                # Use an installed 500 error handler.
                if is_async_callable(self.handler):
                    response = await self.handler(request, exc)
                else:
                    response = await run_in_threadpool(self.handler, request, exc)
    
            if not response_started:
                await response(scope, receive, send)
    
            # We always continue to raise the exception.
            # This allows servers to log the error, or allows test clients
            # to optionally raise the error within the test case.
>           raise exc

.venv/lib/python3.12/site-packages/starlette/middleware/errors.py:186: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <starlette.middleware.errors.ServerErrorMiddleware object at 0x774df44c0aa0>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function ASGITransport.handle_async_request.<locals>.receive at 0x774df44e2c00>
send = <function ASGITransport.handle_async_request.<locals>.send at 0x774df44e3060>

    async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
        if scope["type"] != "http":
            await self.app(scope, receive, send)
            return
    
        response_started = False
    
        async def _send(message: Message) -> None:
            nonlocal response_started, send
    
            if message["type"] == "http.response.start":
                response_started = True
            await send(message)
    
        try:
>           await self.app(scope, receive, _send)

.venv/lib/python3.12/site-packages/starlette/middleware/errors.py:164: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.api.middleware.request_id.RequestIdMiddleware object at 0x774df44c08f0>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function ASGITransport.handle_async_request.<locals>.receive at 0x774df44e2c00>
send = <function ServerErrorMiddleware.__call__.<locals>._send at 0x774df44e3100>

    async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
        if scope["type"] != "http":
            await self.app(scope, receive, send)
            return
    
        request = _CachedRequest(scope, receive)
        wrapped_receive = request.wrapped_receive
        response_sent = anyio.Event()
        app_exc: Exception | None = None
        exception_already_raised = False
    
        async def call_next(request: Request) -> Response:
            async def receive_or_disconnect() -> Message:
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                async with anyio.create_task_group() as task_group:
    
                    async def wrap(func: Callable[[], Awaitable[T]]) -> T:
                        result = await func()
                        task_group.cancel_scope.cancel()
                        return result
    
                    task_group.start_soon(wrap, response_sent.wait)
                    message = await wrap(wrapped_receive)
    
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                return message
    
            async def send_no_error(message: Message) -> None:
                try:
                    await send_stream.send(message)
                except anyio.BrokenResourceError:
                    # recv_stream has been closed, i.e. response_sent has been set.
                    return
    
            async def coro() -> None:
                nonlocal app_exc
    
                with send_stream:
                    try:
                        await self.app(scope, receive_or_disconnect, send_no_error)
                    except Exception as exc:
                        app_exc = exc
    
            task_group.start_soon(coro)
    
            try:
                message = await recv_stream.receive()
                info = message.get("info", None)
                if message["type"] == "http.response.debug" and info is not None:
                    message = await recv_stream.receive()
            except anyio.EndOfStream:
                if app_exc is not None:
                    nonlocal exception_already_raised
                    exception_already_raised = True
                    # Prevent `anyio.EndOfStream` from polluting app exception context.
                    # If both cause and context are None then the context is suppressed
                    # and `anyio.EndOfStream` is not present in the exception traceback.
                    # If exception cause is not None then it is propagated with
                    # reraising here.
                    # If exception has no cause but has context set then the context is
                    # propagated as a cause with the reraise. This is necessary in order
                    # to prevent `anyio.EndOfStream` from polluting the exception
                    # context.
                    raise app_exc from app_exc.__cause__ or app_exc.__context__
                raise RuntimeError("No response returned.")
    
            assert message["type"] == "http.response.start"
    
            async def body_stream() -> BodyStreamGenerator:
                async for message in recv_stream:
                    if message["type"] == "http.response.pathsend":
                        yield message
                        break
                    assert message["type"] == "http.response.body", f"Unexpected message: {message}"
                    body = message.get("body", b"")
                    if body:
                        yield body
                    if not message.get("more_body", False):
                        break
    
            response = _StreamingResponse(status_code=message["status"], content=body_stream(), info=info)
            response.raw_headers = message["headers"]
            return response
    
        streams: anyio.create_memory_object_stream[Message] = anyio.create_memory_object_stream()
        send_stream, recv_stream = streams
>       with recv_stream, send_stream, collapse_excgroups():

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:191: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <contextlib._GeneratorContextManager object at 0x774df44c23f0>
typ = <class 'ExceptionGroup'>
value = ExceptionGroup('unhandled errors in a TaskGroup', [RuntimeError('Task dispatch failed: Retry in 60s: RuntimeError(\'Ex...not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies\\\'}\')')])
traceback = <traceback object at 0x774df4046680>

    def __exit__(self, typ, value, traceback):
        if typ is None:
            try:
                next(self.gen)
            except StopIteration:
                return False
            else:
                try:
                    raise RuntimeError("generator didn't stop")
                finally:
                    self.gen.close()
        else:
            if value is None:
                # Need to force instantiation so we can reliably
                # tell if we get the same exception back
                value = typ()
            try:
>               self.gen.throw(value)

/usr/lib/python3.12/contextlib.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @contextmanager
    def collapse_excgroups() -> Generator[None, None, None]:
        try:
            yield
        except BaseException as exc:
            if has_exceptiongroups:  # pragma: no cover
                while isinstance(exc, BaseExceptionGroup) and len(exc.exceptions) == 1:
                    exc = exc.exceptions[0]
    
>           raise exc

.venv/lib/python3.12/site-packages/starlette/_utils.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.api.middleware.request_id.RequestIdMiddleware object at 0x774df44c08f0>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function ASGITransport.handle_async_request.<locals>.receive at 0x774df44e2c00>
send = <function ServerErrorMiddleware.__call__.<locals>._send at 0x774df44e3100>

    async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
        if scope["type"] != "http":
            await self.app(scope, receive, send)
            return
    
        request = _CachedRequest(scope, receive)
        wrapped_receive = request.wrapped_receive
        response_sent = anyio.Event()
        app_exc: Exception | None = None
        exception_already_raised = False
    
        async def call_next(request: Request) -> Response:
            async def receive_or_disconnect() -> Message:
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                async with anyio.create_task_group() as task_group:
    
                    async def wrap(func: Callable[[], Awaitable[T]]) -> T:
                        result = await func()
                        task_group.cancel_scope.cancel()
                        return result
    
                    task_group.start_soon(wrap, response_sent.wait)
                    message = await wrap(wrapped_receive)
    
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                return message
    
            async def send_no_error(message: Message) -> None:
                try:
                    await send_stream.send(message)
                except anyio.BrokenResourceError:
                    # recv_stream has been closed, i.e. response_sent has been set.
                    return
    
            async def coro() -> None:
                nonlocal app_exc
    
                with send_stream:
                    try:
                        await self.app(scope, receive_or_disconnect, send_no_error)
                    except Exception as exc:
                        app_exc = exc
    
            task_group.start_soon(coro)
    
            try:
                message = await recv_stream.receive()
                info = message.get("info", None)
                if message["type"] == "http.response.debug" and info is not None:
                    message = await recv_stream.receive()
            except anyio.EndOfStream:
                if app_exc is not None:
                    nonlocal exception_already_raised
                    exception_already_raised = True
                    # Prevent `anyio.EndOfStream` from polluting app exception context.
                    # If both cause and context are None then the context is suppressed
                    # and `anyio.EndOfStream` is not present in the exception traceback.
                    # If exception cause is not None then it is propagated with
                    # reraising here.
                    # If exception has no cause but has context set then the context is
                    # propagated as a cause with the reraise. This is necessary in order
                    # to prevent `anyio.EndOfStream` from polluting the exception
                    # context.
                    raise app_exc from app_exc.__cause__ or app_exc.__context__
                raise RuntimeError("No response returned.")
    
            assert message["type"] == "http.response.start"
    
            async def body_stream() -> BodyStreamGenerator:
                async for message in recv_stream:
                    if message["type"] == "http.response.pathsend":
                        yield message
                        break
                    assert message["type"] == "http.response.body", f"Unexpected message: {message}"
                    body = message.get("body", b"")
                    if body:
                        yield body
                    if not message.get("more_body", False):
                        break
    
            response = _StreamingResponse(status_code=message["status"], content=body_stream(), info=info)
            response.raw_headers = message["headers"]
            return response
    
        streams: anyio.create_memory_object_stream[Message] = anyio.create_memory_object_stream()
        send_stream, recv_stream = streams
        with recv_stream, send_stream, collapse_excgroups():
            async with anyio.create_task_group() as task_group:
>               response = await self.dispatch_func(request, call_next)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.api.middleware.request_id.RequestIdMiddleware object at 0x774df44c08f0>
request = <starlette.middleware.base._CachedRequest object at 0x774df44c1820>
call_next = <function BaseHTTPMiddleware.__call__.<locals>.call_next at 0x774df44e31a0>

    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        """Process the request through request ID handling."""
        # Check for client-provided request ID
        client_id = request.headers.get(REQUEST_ID_HEADER)
        request_id: str
    
        if client_id:
            # Validate client ID (must be valid UUID)
            try:
                uuid.UUID(client_id)
                request_id = client_id
            except ValueError:
                # Invalid UUID, generate a new one
                request_id = f"req_{uuid.uuid4().hex}"
        else:
            # Generate new request ID
            request_id = f"req_{uuid.uuid4().hex}"
    
        # Set in context
        set_request_id(RequestId(request_id))
    
        # Store in request state
        request.state.request_id = request_id
    
        # Process request
>       response = await call_next(request)
                   ^^^^^^^^^^^^^^^^^^^^^^^^

src/api/middleware/request_id.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

request = <starlette.middleware.base._CachedRequest object at 0x774df44c1820>

    async def call_next(request: Request) -> Response:
        async def receive_or_disconnect() -> Message:
            if response_sent.is_set():
                return {"type": "http.disconnect"}
    
            async with anyio.create_task_group() as task_group:
    
                async def wrap(func: Callable[[], Awaitable[T]]) -> T:
                    result = await func()
                    task_group.cancel_scope.cancel()
                    return result
    
                task_group.start_soon(wrap, response_sent.wait)
                message = await wrap(wrapped_receive)
    
            if response_sent.is_set():
                return {"type": "http.disconnect"}
    
            return message
    
        async def send_no_error(message: Message) -> None:
            try:
                await send_stream.send(message)
            except anyio.BrokenResourceError:
                # recv_stream has been closed, i.e. response_sent has been set.
                return
    
        async def coro() -> None:
            nonlocal app_exc
    
            with send_stream:
                try:
                    await self.app(scope, receive_or_disconnect, send_no_error)
                except Exception as exc:
                    app_exc = exc
    
        task_group.start_soon(coro)
    
        try:
            message = await recv_stream.receive()
            info = message.get("info", None)
            if message["type"] == "http.response.debug" and info is not None:
                message = await recv_stream.receive()
        except anyio.EndOfStream:
            if app_exc is not None:
                nonlocal exception_already_raised
                exception_already_raised = True
                # Prevent `anyio.EndOfStream` from polluting app exception context.
                # If both cause and context are None then the context is suppressed
                # and `anyio.EndOfStream` is not present in the exception traceback.
                # If exception cause is not None then it is propagated with
                # reraising here.
                # If exception has no cause but has context set then the context is
                # propagated as a cause with the reraise. This is necessary in order
                # to prevent `anyio.EndOfStream` from polluting the exception
                # context.
>               raise app_exc from app_exc.__cause__ or app_exc.__context__

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:168: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    async def coro() -> None:
        nonlocal app_exc
    
        with send_stream:
            try:
>               await self.app(scope, receive_or_disconnect, send_no_error)

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:144: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.api.middleware.timing.TimingMiddleware object at 0x774e0876f170>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774df44e32e0>
send = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.send_no_error at 0x774df44e3380>

    async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
        if scope["type"] != "http":
            await self.app(scope, receive, send)
            return
    
        request = _CachedRequest(scope, receive)
        wrapped_receive = request.wrapped_receive
        response_sent = anyio.Event()
        app_exc: Exception | None = None
        exception_already_raised = False
    
        async def call_next(request: Request) -> Response:
            async def receive_or_disconnect() -> Message:
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                async with anyio.create_task_group() as task_group:
    
                    async def wrap(func: Callable[[], Awaitable[T]]) -> T:
                        result = await func()
                        task_group.cancel_scope.cancel()
                        return result
    
                    task_group.start_soon(wrap, response_sent.wait)
                    message = await wrap(wrapped_receive)
    
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                return message
    
            async def send_no_error(message: Message) -> None:
                try:
                    await send_stream.send(message)
                except anyio.BrokenResourceError:
                    # recv_stream has been closed, i.e. response_sent has been set.
                    return
    
            async def coro() -> None:
                nonlocal app_exc
    
                with send_stream:
                    try:
                        await self.app(scope, receive_or_disconnect, send_no_error)
                    except Exception as exc:
                        app_exc = exc
    
            task_group.start_soon(coro)
    
            try:
                message = await recv_stream.receive()
                info = message.get("info", None)
                if message["type"] == "http.response.debug" and info is not None:
                    message = await recv_stream.receive()
            except anyio.EndOfStream:
                if app_exc is not None:
                    nonlocal exception_already_raised
                    exception_already_raised = True
                    # Prevent `anyio.EndOfStream` from polluting app exception context.
                    # If both cause and context are None then the context is suppressed
                    # and `anyio.EndOfStream` is not present in the exception traceback.
                    # If exception cause is not None then it is propagated with
                    # reraising here.
                    # If exception has no cause but has context set then the context is
                    # propagated as a cause with the reraise. This is necessary in order
                    # to prevent `anyio.EndOfStream` from polluting the exception
                    # context.
                    raise app_exc from app_exc.__cause__ or app_exc.__context__
                raise RuntimeError("No response returned.")
    
            assert message["type"] == "http.response.start"
    
            async def body_stream() -> BodyStreamGenerator:
                async for message in recv_stream:
                    if message["type"] == "http.response.pathsend":
                        yield message
                        break
                    assert message["type"] == "http.response.body", f"Unexpected message: {message}"
                    body = message.get("body", b"")
                    if body:
                        yield body
                    if not message.get("more_body", False):
                        break
    
            response = _StreamingResponse(status_code=message["status"], content=body_stream(), info=info)
            response.raw_headers = message["headers"]
            return response
    
        streams: anyio.create_memory_object_stream[Message] = anyio.create_memory_object_stream()
        send_stream, recv_stream = streams
>       with recv_stream, send_stream, collapse_excgroups():

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:191: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <contextlib._GeneratorContextManager object at 0x774df44c8e60>
typ = <class 'ExceptionGroup'>
value = ExceptionGroup('unhandled errors in a TaskGroup', [RuntimeError('Task dispatch failed: Retry in 60s: RuntimeError(\'Ex...not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies\\\'}\')')])
traceback = <traceback object at 0x774df4046c40>

    def __exit__(self, typ, value, traceback):
        if typ is None:
            try:
                next(self.gen)
            except StopIteration:
                return False
            else:
                try:
                    raise RuntimeError("generator didn't stop")
                finally:
                    self.gen.close()
        else:
            if value is None:
                # Need to force instantiation so we can reliably
                # tell if we get the same exception back
                value = typ()
            try:
>               self.gen.throw(value)

/usr/lib/python3.12/contextlib.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @contextmanager
    def collapse_excgroups() -> Generator[None, None, None]:
        try:
            yield
        except BaseException as exc:
            if has_exceptiongroups:  # pragma: no cover
                while isinstance(exc, BaseExceptionGroup) and len(exc.exceptions) == 1:
                    exc = exc.exceptions[0]
    
>           raise exc

.venv/lib/python3.12/site-packages/starlette/_utils.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.api.middleware.timing.TimingMiddleware object at 0x774e0876f170>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774df44e32e0>
send = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.send_no_error at 0x774df44e3380>

    async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
        if scope["type"] != "http":
            await self.app(scope, receive, send)
            return
    
        request = _CachedRequest(scope, receive)
        wrapped_receive = request.wrapped_receive
        response_sent = anyio.Event()
        app_exc: Exception | None = None
        exception_already_raised = False
    
        async def call_next(request: Request) -> Response:
            async def receive_or_disconnect() -> Message:
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                async with anyio.create_task_group() as task_group:
    
                    async def wrap(func: Callable[[], Awaitable[T]]) -> T:
                        result = await func()
                        task_group.cancel_scope.cancel()
                        return result
    
                    task_group.start_soon(wrap, response_sent.wait)
                    message = await wrap(wrapped_receive)
    
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                return message
    
            async def send_no_error(message: Message) -> None:
                try:
                    await send_stream.send(message)
                except anyio.BrokenResourceError:
                    # recv_stream has been closed, i.e. response_sent has been set.
                    return
    
            async def coro() -> None:
                nonlocal app_exc
    
                with send_stream:
                    try:
                        await self.app(scope, receive_or_disconnect, send_no_error)
                    except Exception as exc:
                        app_exc = exc
    
            task_group.start_soon(coro)
    
            try:
                message = await recv_stream.receive()
                info = message.get("info", None)
                if message["type"] == "http.response.debug" and info is not None:
                    message = await recv_stream.receive()
            except anyio.EndOfStream:
                if app_exc is not None:
                    nonlocal exception_already_raised
                    exception_already_raised = True
                    # Prevent `anyio.EndOfStream` from polluting app exception context.
                    # If both cause and context are None then the context is suppressed
                    # and `anyio.EndOfStream` is not present in the exception traceback.
                    # If exception cause is not None then it is propagated with
                    # reraising here.
                    # If exception has no cause but has context set then the context is
                    # propagated as a cause with the reraise. This is necessary in order
                    # to prevent `anyio.EndOfStream` from polluting the exception
                    # context.
                    raise app_exc from app_exc.__cause__ or app_exc.__context__
                raise RuntimeError("No response returned.")
    
            assert message["type"] == "http.response.start"
    
            async def body_stream() -> BodyStreamGenerator:
                async for message in recv_stream:
                    if message["type"] == "http.response.pathsend":
                        yield message
                        break
                    assert message["type"] == "http.response.body", f"Unexpected message: {message}"
                    body = message.get("body", b"")
                    if body:
                        yield body
                    if not message.get("more_body", False):
                        break
    
            response = _StreamingResponse(status_code=message["status"], content=body_stream(), info=info)
            response.raw_headers = message["headers"]
            return response
    
        streams: anyio.create_memory_object_stream[Message] = anyio.create_memory_object_stream()
        send_stream, recv_stream = streams
        with recv_stream, send_stream, collapse_excgroups():
            async with anyio.create_task_group() as task_group:
>               response = await self.dispatch_func(request, call_next)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.api.middleware.timing.TimingMiddleware object at 0x774e0876f170>
request = <starlette.middleware.base._CachedRequest object at 0x774df44c8500>
call_next = <function BaseHTTPMiddleware.__call__.<locals>.call_next at 0x774df44e3560>

    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        """Process the request through timing."""
        start_time = time.perf_counter()
    
>       response = await call_next(request)
                   ^^^^^^^^^^^^^^^^^^^^^^^^

src/api/middleware/timing.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

request = <starlette.middleware.base._CachedRequest object at 0x774df44c8500>

    async def call_next(request: Request) -> Response:
        async def receive_or_disconnect() -> Message:
            if response_sent.is_set():
                return {"type": "http.disconnect"}
    
            async with anyio.create_task_group() as task_group:
    
                async def wrap(func: Callable[[], Awaitable[T]]) -> T:
                    result = await func()
                    task_group.cancel_scope.cancel()
                    return result
    
                task_group.start_soon(wrap, response_sent.wait)
                message = await wrap(wrapped_receive)
    
            if response_sent.is_set():
                return {"type": "http.disconnect"}
    
            return message
    
        async def send_no_error(message: Message) -> None:
            try:
                await send_stream.send(message)
            except anyio.BrokenResourceError:
                # recv_stream has been closed, i.e. response_sent has been set.
                return
    
        async def coro() -> None:
            nonlocal app_exc
    
            with send_stream:
                try:
                    await self.app(scope, receive_or_disconnect, send_no_error)
                except Exception as exc:
                    app_exc = exc
    
        task_group.start_soon(coro)
    
        try:
            message = await recv_stream.receive()
            info = message.get("info", None)
            if message["type"] == "http.response.debug" and info is not None:
                message = await recv_stream.receive()
        except anyio.EndOfStream:
            if app_exc is not None:
                nonlocal exception_already_raised
                exception_already_raised = True
                # Prevent `anyio.EndOfStream` from polluting app exception context.
                # If both cause and context are None then the context is suppressed
                # and `anyio.EndOfStream` is not present in the exception traceback.
                # If exception cause is not None then it is propagated with
                # reraising here.
                # If exception has no cause but has context set then the context is
                # propagated as a cause with the reraise. This is necessary in order
                # to prevent `anyio.EndOfStream` from polluting the exception
                # context.
>               raise app_exc from app_exc.__cause__ or app_exc.__context__

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:168: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    async def coro() -> None:
        nonlocal app_exc
    
        with send_stream:
            try:
>               await self.app(scope, receive_or_disconnect, send_no_error)

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:144: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.core.admin_ops.infrastructure.observability.middleware.StructuredLoggingMiddleware object at 0x774df44c0740>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774df44e3600>
send = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.send_no_error at 0x774df44e36a0>

    async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
        if scope["type"] != "http":
            await self.app(scope, receive, send)
            return
    
        request = _CachedRequest(scope, receive)
        wrapped_receive = request.wrapped_receive
        response_sent = anyio.Event()
        app_exc: Exception | None = None
        exception_already_raised = False
    
        async def call_next(request: Request) -> Response:
            async def receive_or_disconnect() -> Message:
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                async with anyio.create_task_group() as task_group:
    
                    async def wrap(func: Callable[[], Awaitable[T]]) -> T:
                        result = await func()
                        task_group.cancel_scope.cancel()
                        return result
    
                    task_group.start_soon(wrap, response_sent.wait)
                    message = await wrap(wrapped_receive)
    
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                return message
    
            async def send_no_error(message: Message) -> None:
                try:
                    await send_stream.send(message)
                except anyio.BrokenResourceError:
                    # recv_stream has been closed, i.e. response_sent has been set.
                    return
    
            async def coro() -> None:
                nonlocal app_exc
    
                with send_stream:
                    try:
                        await self.app(scope, receive_or_disconnect, send_no_error)
                    except Exception as exc:
                        app_exc = exc
    
            task_group.start_soon(coro)
    
            try:
                message = await recv_stream.receive()
                info = message.get("info", None)
                if message["type"] == "http.response.debug" and info is not None:
                    message = await recv_stream.receive()
            except anyio.EndOfStream:
                if app_exc is not None:
                    nonlocal exception_already_raised
                    exception_already_raised = True
                    # Prevent `anyio.EndOfStream` from polluting app exception context.
                    # If both cause and context are None then the context is suppressed
                    # and `anyio.EndOfStream` is not present in the exception traceback.
                    # If exception cause is not None then it is propagated with
                    # reraising here.
                    # If exception has no cause but has context set then the context is
                    # propagated as a cause with the reraise. This is necessary in order
                    # to prevent `anyio.EndOfStream` from polluting the exception
                    # context.
                    raise app_exc from app_exc.__cause__ or app_exc.__context__
                raise RuntimeError("No response returned.")
    
            assert message["type"] == "http.response.start"
    
            async def body_stream() -> BodyStreamGenerator:
                async for message in recv_stream:
                    if message["type"] == "http.response.pathsend":
                        yield message
                        break
                    assert message["type"] == "http.response.body", f"Unexpected message: {message}"
                    body = message.get("body", b"")
                    if body:
                        yield body
                    if not message.get("more_body", False):
                        break
    
            response = _StreamingResponse(status_code=message["status"], content=body_stream(), info=info)
            response.raw_headers = message["headers"]
            return response
    
        streams: anyio.create_memory_object_stream[Message] = anyio.create_memory_object_stream()
        send_stream, recv_stream = streams
>       with recv_stream, send_stream, collapse_excgroups():

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:191: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <contextlib._GeneratorContextManager object at 0x774df44d0140>
typ = <class 'ExceptionGroup'>
value = ExceptionGroup('unhandled errors in a TaskGroup', [RuntimeError('Task dispatch failed: Retry in 60s: RuntimeError(\'Ex...not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies\\\'}\')')])
traceback = <traceback object at 0x774df4047f40>

    def __exit__(self, typ, value, traceback):
        if typ is None:
            try:
                next(self.gen)
            except StopIteration:
                return False
            else:
                try:
                    raise RuntimeError("generator didn't stop")
                finally:
                    self.gen.close()
        else:
            if value is None:
                # Need to force instantiation so we can reliably
                # tell if we get the same exception back
                value = typ()
            try:
>               self.gen.throw(value)

/usr/lib/python3.12/contextlib.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @contextmanager
    def collapse_excgroups() -> Generator[None, None, None]:
        try:
            yield
        except BaseException as exc:
            if has_exceptiongroups:  # pragma: no cover
                while isinstance(exc, BaseExceptionGroup) and len(exc.exceptions) == 1:
                    exc = exc.exceptions[0]
    
>           raise exc

.venv/lib/python3.12/site-packages/starlette/_utils.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.core.admin_ops.infrastructure.observability.middleware.StructuredLoggingMiddleware object at 0x774df44c0740>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774df44e3600>
send = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.send_no_error at 0x774df44e36a0>

    async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
        if scope["type"] != "http":
            await self.app(scope, receive, send)
            return
    
        request = _CachedRequest(scope, receive)
        wrapped_receive = request.wrapped_receive
        response_sent = anyio.Event()
        app_exc: Exception | None = None
        exception_already_raised = False
    
        async def call_next(request: Request) -> Response:
            async def receive_or_disconnect() -> Message:
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                async with anyio.create_task_group() as task_group:
    
                    async def wrap(func: Callable[[], Awaitable[T]]) -> T:
                        result = await func()
                        task_group.cancel_scope.cancel()
                        return result
    
                    task_group.start_soon(wrap, response_sent.wait)
                    message = await wrap(wrapped_receive)
    
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                return message
    
            async def send_no_error(message: Message) -> None:
                try:
                    await send_stream.send(message)
                except anyio.BrokenResourceError:
                    # recv_stream has been closed, i.e. response_sent has been set.
                    return
    
            async def coro() -> None:
                nonlocal app_exc
    
                with send_stream:
                    try:
                        await self.app(scope, receive_or_disconnect, send_no_error)
                    except Exception as exc:
                        app_exc = exc
    
            task_group.start_soon(coro)
    
            try:
                message = await recv_stream.receive()
                info = message.get("info", None)
                if message["type"] == "http.response.debug" and info is not None:
                    message = await recv_stream.receive()
            except anyio.EndOfStream:
                if app_exc is not None:
                    nonlocal exception_already_raised
                    exception_already_raised = True
                    # Prevent `anyio.EndOfStream` from polluting app exception context.
                    # If both cause and context are None then the context is suppressed
                    # and `anyio.EndOfStream` is not present in the exception traceback.
                    # If exception cause is not None then it is propagated with
                    # reraising here.
                    # If exception has no cause but has context set then the context is
                    # propagated as a cause with the reraise. This is necessary in order
                    # to prevent `anyio.EndOfStream` from polluting the exception
                    # context.
                    raise app_exc from app_exc.__cause__ or app_exc.__context__
                raise RuntimeError("No response returned.")
    
            assert message["type"] == "http.response.start"
    
            async def body_stream() -> BodyStreamGenerator:
                async for message in recv_stream:
                    if message["type"] == "http.response.pathsend":
                        yield message
                        break
                    assert message["type"] == "http.response.body", f"Unexpected message: {message}"
                    body = message.get("body", b"")
                    if body:
                        yield body
                    if not message.get("more_body", False):
                        break
    
            response = _StreamingResponse(status_code=message["status"], content=body_stream(), info=info)
            response.raw_headers = message["headers"]
            return response
    
        streams: anyio.create_memory_object_stream[Message] = anyio.create_memory_object_stream()
        send_stream, recv_stream = streams
        with recv_stream, send_stream, collapse_excgroups():
            async with anyio.create_task_group() as task_group:
>               response = await self.dispatch_func(request, call_next)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.core.admin_ops.infrastructure.observability.middleware.StructuredLoggingMiddleware object at 0x774df44c0740>
request = <starlette.middleware.base._CachedRequest object at 0x774df44cb6e0>
call_next = <function BaseHTTPMiddleware.__call__.<locals>.call_next at 0x774df44e3920>

    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        start_time = time.perf_counter()
    
        path = request.url.path
        method = request.method
    
        # Skip health checks to avoid log noise
        if path.endswith("/health") or path.endswith("/ready"):
            return await call_next(request)
    
        try:
            response = await call_next(request)
    
            latency = (time.perf_counter() - start_time) * 1000
    
            log_data = {
                "method": method,
                "path": path,
                "status_code": response.status_code,
                "latency_ms": round(latency, 2),
                "ip": request.client.host if request.client else None,
            }
    
            # Log level depends on status code
            if response.status_code >= 500:
                logger.error("Request failed", extra={"props": log_data})
            elif response.status_code >= 400:
                logger.warning("Request bad input", extra={"props": log_data})
            else:
                logger.info("Request processed", extra={"props": log_data})
    
            return response
    
        except Exception as e:
            latency = (time.perf_counter() - start_time) * 1000
            logger.error(
                f"Request exception: {str(e)}",
                extra={
                    "props": {
                        "method": method,
                        "path": path,
                        "status_code": 500,
                        "latency_ms": round(latency, 2),
                    }
                },
            )
>           raise e

src/core/admin_ops/infrastructure/observability/middleware.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.core.admin_ops.infrastructure.observability.middleware.StructuredLoggingMiddleware object at 0x774df44c0740>
request = <starlette.middleware.base._CachedRequest object at 0x774df44cb6e0>
call_next = <function BaseHTTPMiddleware.__call__.<locals>.call_next at 0x774df44e3920>

    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        start_time = time.perf_counter()
    
        path = request.url.path
        method = request.method
    
        # Skip health checks to avoid log noise
        if path.endswith("/health") or path.endswith("/ready"):
            return await call_next(request)
    
        try:
>           response = await call_next(request)
                       ^^^^^^^^^^^^^^^^^^^^^^^^

src/core/admin_ops/infrastructure/observability/middleware.py:61: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

request = <starlette.middleware.base._CachedRequest object at 0x774df44cb6e0>

    async def call_next(request: Request) -> Response:
        async def receive_or_disconnect() -> Message:
            if response_sent.is_set():
                return {"type": "http.disconnect"}
    
            async with anyio.create_task_group() as task_group:
    
                async def wrap(func: Callable[[], Awaitable[T]]) -> T:
                    result = await func()
                    task_group.cancel_scope.cancel()
                    return result
    
                task_group.start_soon(wrap, response_sent.wait)
                message = await wrap(wrapped_receive)
    
            if response_sent.is_set():
                return {"type": "http.disconnect"}
    
            return message
    
        async def send_no_error(message: Message) -> None:
            try:
                await send_stream.send(message)
            except anyio.BrokenResourceError:
                # recv_stream has been closed, i.e. response_sent has been set.
                return
    
        async def coro() -> None:
            nonlocal app_exc
    
            with send_stream:
                try:
                    await self.app(scope, receive_or_disconnect, send_no_error)
                except Exception as exc:
                    app_exc = exc
    
        task_group.start_soon(coro)
    
        try:
            message = await recv_stream.receive()
            info = message.get("info", None)
            if message["type"] == "http.response.debug" and info is not None:
                message = await recv_stream.receive()
        except anyio.EndOfStream:
            if app_exc is not None:
                nonlocal exception_already_raised
                exception_already_raised = True
                # Prevent `anyio.EndOfStream` from polluting app exception context.
                # If both cause and context are None then the context is suppressed
                # and `anyio.EndOfStream` is not present in the exception traceback.
                # If exception cause is not None then it is propagated with
                # reraising here.
                # If exception has no cause but has context set then the context is
                # propagated as a cause with the reraise. This is necessary in order
                # to prevent `anyio.EndOfStream` from polluting the exception
                # context.
>               raise app_exc from app_exc.__cause__ or app_exc.__context__

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:168: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    async def coro() -> None:
        nonlocal app_exc
    
        with send_stream:
            try:
>               await self.app(scope, receive_or_disconnect, send_no_error)

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:144: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.api.middleware.rate_limit.RateLimitMiddleware object at 0x774df44c0590>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774df44e39c0>
send = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.send_no_error at 0x774df44e3a60>

    async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
        if scope["type"] != "http":
            await self.app(scope, receive, send)
            return
    
        request = _CachedRequest(scope, receive)
        wrapped_receive = request.wrapped_receive
        response_sent = anyio.Event()
        app_exc: Exception | None = None
        exception_already_raised = False
    
        async def call_next(request: Request) -> Response:
            async def receive_or_disconnect() -> Message:
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                async with anyio.create_task_group() as task_group:
    
                    async def wrap(func: Callable[[], Awaitable[T]]) -> T:
                        result = await func()
                        task_group.cancel_scope.cancel()
                        return result
    
                    task_group.start_soon(wrap, response_sent.wait)
                    message = await wrap(wrapped_receive)
    
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                return message
    
            async def send_no_error(message: Message) -> None:
                try:
                    await send_stream.send(message)
                except anyio.BrokenResourceError:
                    # recv_stream has been closed, i.e. response_sent has been set.
                    return
    
            async def coro() -> None:
                nonlocal app_exc
    
                with send_stream:
                    try:
                        await self.app(scope, receive_or_disconnect, send_no_error)
                    except Exception as exc:
                        app_exc = exc
    
            task_group.start_soon(coro)
    
            try:
                message = await recv_stream.receive()
                info = message.get("info", None)
                if message["type"] == "http.response.debug" and info is not None:
                    message = await recv_stream.receive()
            except anyio.EndOfStream:
                if app_exc is not None:
                    nonlocal exception_already_raised
                    exception_already_raised = True
                    # Prevent `anyio.EndOfStream` from polluting app exception context.
                    # If both cause and context are None then the context is suppressed
                    # and `anyio.EndOfStream` is not present in the exception traceback.
                    # If exception cause is not None then it is propagated with
                    # reraising here.
                    # If exception has no cause but has context set then the context is
                    # propagated as a cause with the reraise. This is necessary in order
                    # to prevent `anyio.EndOfStream` from polluting the exception
                    # context.
                    raise app_exc from app_exc.__cause__ or app_exc.__context__
                raise RuntimeError("No response returned.")
    
            assert message["type"] == "http.response.start"
    
            async def body_stream() -> BodyStreamGenerator:
                async for message in recv_stream:
                    if message["type"] == "http.response.pathsend":
                        yield message
                        break
                    assert message["type"] == "http.response.body", f"Unexpected message: {message}"
                    body = message.get("body", b"")
                    if body:
                        yield body
                    if not message.get("more_body", False):
                        break
    
            response = _StreamingResponse(status_code=message["status"], content=body_stream(), info=info)
            response.raw_headers = message["headers"]
            return response
    
        streams: anyio.create_memory_object_stream[Message] = anyio.create_memory_object_stream()
        send_stream, recv_stream = streams
>       with recv_stream, send_stream, collapse_excgroups():

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:191: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <contextlib._GeneratorContextManager object at 0x774df44d3230>
typ = <class 'ExceptionGroup'>
value = ExceptionGroup('unhandled errors in a TaskGroup', [RuntimeError('Task dispatch failed: Retry in 60s: RuntimeError(\'Ex...not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies\\\'}\')')])
traceback = <traceback object at 0x774df4050180>

    def __exit__(self, typ, value, traceback):
        if typ is None:
            try:
                next(self.gen)
            except StopIteration:
                return False
            else:
                try:
                    raise RuntimeError("generator didn't stop")
                finally:
                    self.gen.close()
        else:
            if value is None:
                # Need to force instantiation so we can reliably
                # tell if we get the same exception back
                value = typ()
            try:
>               self.gen.throw(value)

/usr/lib/python3.12/contextlib.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @contextmanager
    def collapse_excgroups() -> Generator[None, None, None]:
        try:
            yield
        except BaseException as exc:
            if has_exceptiongroups:  # pragma: no cover
                while isinstance(exc, BaseExceptionGroup) and len(exc.exceptions) == 1:
                    exc = exc.exceptions[0]
    
>           raise exc

.venv/lib/python3.12/site-packages/starlette/_utils.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.api.middleware.rate_limit.RateLimitMiddleware object at 0x774df44c0590>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774df44e39c0>
send = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.send_no_error at 0x774df44e3a60>

    async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
        if scope["type"] != "http":
            await self.app(scope, receive, send)
            return
    
        request = _CachedRequest(scope, receive)
        wrapped_receive = request.wrapped_receive
        response_sent = anyio.Event()
        app_exc: Exception | None = None
        exception_already_raised = False
    
        async def call_next(request: Request) -> Response:
            async def receive_or_disconnect() -> Message:
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                async with anyio.create_task_group() as task_group:
    
                    async def wrap(func: Callable[[], Awaitable[T]]) -> T:
                        result = await func()
                        task_group.cancel_scope.cancel()
                        return result
    
                    task_group.start_soon(wrap, response_sent.wait)
                    message = await wrap(wrapped_receive)
    
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                return message
    
            async def send_no_error(message: Message) -> None:
                try:
                    await send_stream.send(message)
                except anyio.BrokenResourceError:
                    # recv_stream has been closed, i.e. response_sent has been set.
                    return
    
            async def coro() -> None:
                nonlocal app_exc
    
                with send_stream:
                    try:
                        await self.app(scope, receive_or_disconnect, send_no_error)
                    except Exception as exc:
                        app_exc = exc
    
            task_group.start_soon(coro)
    
            try:
                message = await recv_stream.receive()
                info = message.get("info", None)
                if message["type"] == "http.response.debug" and info is not None:
                    message = await recv_stream.receive()
            except anyio.EndOfStream:
                if app_exc is not None:
                    nonlocal exception_already_raised
                    exception_already_raised = True
                    # Prevent `anyio.EndOfStream` from polluting app exception context.
                    # If both cause and context are None then the context is suppressed
                    # and `anyio.EndOfStream` is not present in the exception traceback.
                    # If exception cause is not None then it is propagated with
                    # reraising here.
                    # If exception has no cause but has context set then the context is
                    # propagated as a cause with the reraise. This is necessary in order
                    # to prevent `anyio.EndOfStream` from polluting the exception
                    # context.
                    raise app_exc from app_exc.__cause__ or app_exc.__context__
                raise RuntimeError("No response returned.")
    
            assert message["type"] == "http.response.start"
    
            async def body_stream() -> BodyStreamGenerator:
                async for message in recv_stream:
                    if message["type"] == "http.response.pathsend":
                        yield message
                        break
                    assert message["type"] == "http.response.body", f"Unexpected message: {message}"
                    body = message.get("body", b"")
                    if body:
                        yield body
                    if not message.get("more_body", False):
                        break
    
            response = _StreamingResponse(status_code=message["status"], content=body_stream(), info=info)
            response.raw_headers = message["headers"]
            return response
    
        streams: anyio.create_memory_object_stream[Message] = anyio.create_memory_object_stream()
        send_stream, recv_stream = streams
        with recv_stream, send_stream, collapse_excgroups():
            async with anyio.create_task_group() as task_group:
>               response = await self.dispatch_func(request, call_next)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.api.middleware.rate_limit.RateLimitMiddleware object at 0x774df44c0590>
request = <starlette.middleware.base._CachedRequest object at 0x774df44d2810>
call_next = <function BaseHTTPMiddleware.__call__.<locals>.call_next at 0x774df44e3d80>

    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        """Process the request through rate limiting."""
        path = request.url.path
        method = request.method
        origin = request.headers.get("Origin", "*")
    
        # Determine rate limit category
        category = _get_category(path, method)
        if category is None:
            return await call_next(request)
    
        # Get tenant ID (set by auth middleware)
        tenant_id = get_current_tenant()
        if tenant_id is None:
            # If no tenant (before auth), use IP address as identifier
            tenant_id = request.client.host or "anonymous"
    
        # Check rate limit
        try:
            result = await _get_rate_limiter().check(str(tenant_id), category)
        except Exception as e:
            # Fail open if rate limiter fails (e.g. Redis down)
            logger.warning(f"Rate limiter failed (fail open): {e}")
            return await call_next(request)
    
        if not result.allowed:
            logger.warning(
                f"Rate limit exceeded: tenant={tenant_id}, category={category.value}, "
                f"path={method} {path}"
            )
            response = JSONResponse(
                status_code=429,
                content={
                    "error": {
                        "code": "RATE_LIMIT_EXCEEDED",
                        "message": f"Too many requests. Please retry after {result.retry_after} seconds.",
                        "retry_after": result.retry_after,
                    }
                },
                headers={
                    "Retry-After": str(result.retry_after),
                    "X-RateLimit-Limit": str(result.limit),
                    "X-RateLimit-Remaining": "0",
                    "X-RateLimit-Reset": str(result.reset_at),
                },
            )
            return _add_cors_headers(response, origin)
    
        # Proceed with request
>       response = await call_next(request)
                   ^^^^^^^^^^^^^^^^^^^^^^^^

src/api/middleware/rate_limit.py:135: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

request = <starlette.middleware.base._CachedRequest object at 0x774df44d2810>

    async def call_next(request: Request) -> Response:
        async def receive_or_disconnect() -> Message:
            if response_sent.is_set():
                return {"type": "http.disconnect"}
    
            async with anyio.create_task_group() as task_group:
    
                async def wrap(func: Callable[[], Awaitable[T]]) -> T:
                    result = await func()
                    task_group.cancel_scope.cancel()
                    return result
    
                task_group.start_soon(wrap, response_sent.wait)
                message = await wrap(wrapped_receive)
    
            if response_sent.is_set():
                return {"type": "http.disconnect"}
    
            return message
    
        async def send_no_error(message: Message) -> None:
            try:
                await send_stream.send(message)
            except anyio.BrokenResourceError:
                # recv_stream has been closed, i.e. response_sent has been set.
                return
    
        async def coro() -> None:
            nonlocal app_exc
    
            with send_stream:
                try:
                    await self.app(scope, receive_or_disconnect, send_no_error)
                except Exception as exc:
                    app_exc = exc
    
        task_group.start_soon(coro)
    
        try:
            message = await recv_stream.receive()
            info = message.get("info", None)
            if message["type"] == "http.response.debug" and info is not None:
                message = await recv_stream.receive()
        except anyio.EndOfStream:
            if app_exc is not None:
                nonlocal exception_already_raised
                exception_already_raised = True
                # Prevent `anyio.EndOfStream` from polluting app exception context.
                # If both cause and context are None then the context is suppressed
                # and `anyio.EndOfStream` is not present in the exception traceback.
                # If exception cause is not None then it is propagated with
                # reraising here.
                # If exception has no cause but has context set then the context is
                # propagated as a cause with the reraise. This is necessary in order
                # to prevent `anyio.EndOfStream` from polluting the exception
                # context.
>               raise app_exc from app_exc.__cause__ or app_exc.__context__

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:168: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    async def coro() -> None:
        nonlocal app_exc
    
        with send_stream:
            try:
>               await self.app(scope, receive_or_disconnect, send_no_error)

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:144: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.api.middleware.auth.AuthenticationMiddleware object at 0x774df44c0080>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774e2970bc40>
send = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.send_no_error at 0x774df44e3f60>

    async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
        if scope["type"] != "http":
            await self.app(scope, receive, send)
            return
    
        request = _CachedRequest(scope, receive)
        wrapped_receive = request.wrapped_receive
        response_sent = anyio.Event()
        app_exc: Exception | None = None
        exception_already_raised = False
    
        async def call_next(request: Request) -> Response:
            async def receive_or_disconnect() -> Message:
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                async with anyio.create_task_group() as task_group:
    
                    async def wrap(func: Callable[[], Awaitable[T]]) -> T:
                        result = await func()
                        task_group.cancel_scope.cancel()
                        return result
    
                    task_group.start_soon(wrap, response_sent.wait)
                    message = await wrap(wrapped_receive)
    
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                return message
    
            async def send_no_error(message: Message) -> None:
                try:
                    await send_stream.send(message)
                except anyio.BrokenResourceError:
                    # recv_stream has been closed, i.e. response_sent has been set.
                    return
    
            async def coro() -> None:
                nonlocal app_exc
    
                with send_stream:
                    try:
                        await self.app(scope, receive_or_disconnect, send_no_error)
                    except Exception as exc:
                        app_exc = exc
    
            task_group.start_soon(coro)
    
            try:
                message = await recv_stream.receive()
                info = message.get("info", None)
                if message["type"] == "http.response.debug" and info is not None:
                    message = await recv_stream.receive()
            except anyio.EndOfStream:
                if app_exc is not None:
                    nonlocal exception_already_raised
                    exception_already_raised = True
                    # Prevent `anyio.EndOfStream` from polluting app exception context.
                    # If both cause and context are None then the context is suppressed
                    # and `anyio.EndOfStream` is not present in the exception traceback.
                    # If exception cause is not None then it is propagated with
                    # reraising here.
                    # If exception has no cause but has context set then the context is
                    # propagated as a cause with the reraise. This is necessary in order
                    # to prevent `anyio.EndOfStream` from polluting the exception
                    # context.
                    raise app_exc from app_exc.__cause__ or app_exc.__context__
                raise RuntimeError("No response returned.")
    
            assert message["type"] == "http.response.start"
    
            async def body_stream() -> BodyStreamGenerator:
                async for message in recv_stream:
                    if message["type"] == "http.response.pathsend":
                        yield message
                        break
                    assert message["type"] == "http.response.body", f"Unexpected message: {message}"
                    body = message.get("body", b"")
                    if body:
                        yield body
                    if not message.get("more_body", False):
                        break
    
            response = _StreamingResponse(status_code=message["status"], content=body_stream(), info=info)
            response.raw_headers = message["headers"]
            return response
    
        streams: anyio.create_memory_object_stream[Message] = anyio.create_memory_object_stream()
        send_stream, recv_stream = streams
>       with recv_stream, send_stream, collapse_excgroups():

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:191: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <contextlib._GeneratorContextManager object at 0x774df44ead80>
typ = <class 'ExceptionGroup'>
value = ExceptionGroup('unhandled errors in a TaskGroup', [RuntimeError('Task dispatch failed: Retry in 60s: RuntimeError(\'Ex...not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies\\\'}\')')])
traceback = <traceback object at 0x774df4050d00>

    def __exit__(self, typ, value, traceback):
        if typ is None:
            try:
                next(self.gen)
            except StopIteration:
                return False
            else:
                try:
                    raise RuntimeError("generator didn't stop")
                finally:
                    self.gen.close()
        else:
            if value is None:
                # Need to force instantiation so we can reliably
                # tell if we get the same exception back
                value = typ()
            try:
>               self.gen.throw(value)

/usr/lib/python3.12/contextlib.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @contextmanager
    def collapse_excgroups() -> Generator[None, None, None]:
        try:
            yield
        except BaseException as exc:
            if has_exceptiongroups:  # pragma: no cover
                while isinstance(exc, BaseExceptionGroup) and len(exc.exceptions) == 1:
                    exc = exc.exceptions[0]
    
>           raise exc

.venv/lib/python3.12/site-packages/starlette/_utils.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.api.middleware.auth.AuthenticationMiddleware object at 0x774df44c0080>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774e2970bc40>
send = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.send_no_error at 0x774df44e3f60>

    async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
        if scope["type"] != "http":
            await self.app(scope, receive, send)
            return
    
        request = _CachedRequest(scope, receive)
        wrapped_receive = request.wrapped_receive
        response_sent = anyio.Event()
        app_exc: Exception | None = None
        exception_already_raised = False
    
        async def call_next(request: Request) -> Response:
            async def receive_or_disconnect() -> Message:
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                async with anyio.create_task_group() as task_group:
    
                    async def wrap(func: Callable[[], Awaitable[T]]) -> T:
                        result = await func()
                        task_group.cancel_scope.cancel()
                        return result
    
                    task_group.start_soon(wrap, response_sent.wait)
                    message = await wrap(wrapped_receive)
    
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                return message
    
            async def send_no_error(message: Message) -> None:
                try:
                    await send_stream.send(message)
                except anyio.BrokenResourceError:
                    # recv_stream has been closed, i.e. response_sent has been set.
                    return
    
            async def coro() -> None:
                nonlocal app_exc
    
                with send_stream:
                    try:
                        await self.app(scope, receive_or_disconnect, send_no_error)
                    except Exception as exc:
                        app_exc = exc
    
            task_group.start_soon(coro)
    
            try:
                message = await recv_stream.receive()
                info = message.get("info", None)
                if message["type"] == "http.response.debug" and info is not None:
                    message = await recv_stream.receive()
            except anyio.EndOfStream:
                if app_exc is not None:
                    nonlocal exception_already_raised
                    exception_already_raised = True
                    # Prevent `anyio.EndOfStream` from polluting app exception context.
                    # If both cause and context are None then the context is suppressed
                    # and `anyio.EndOfStream` is not present in the exception traceback.
                    # If exception cause is not None then it is propagated with
                    # reraising here.
                    # If exception has no cause but has context set then the context is
                    # propagated as a cause with the reraise. This is necessary in order
                    # to prevent `anyio.EndOfStream` from polluting the exception
                    # context.
                    raise app_exc from app_exc.__cause__ or app_exc.__context__
                raise RuntimeError("No response returned.")
    
            assert message["type"] == "http.response.start"
    
            async def body_stream() -> BodyStreamGenerator:
                async for message in recv_stream:
                    if message["type"] == "http.response.pathsend":
                        yield message
                        break
                    assert message["type"] == "http.response.body", f"Unexpected message: {message}"
                    body = message.get("body", b"")
                    if body:
                        yield body
                    if not message.get("more_body", False):
                        break
    
            response = _StreamingResponse(status_code=message["status"], content=body_stream(), info=info)
            response.raw_headers = message["headers"]
            return response
    
        streams: anyio.create_memory_object_stream[Message] = anyio.create_memory_object_stream()
        send_stream, recv_stream = streams
        with recv_stream, send_stream, collapse_excgroups():
            async with anyio.create_task_group() as task_group:
>               response = await self.dispatch_func(request, call_next)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.api.middleware.auth.AuthenticationMiddleware object at 0x774df44c0080>
request = <starlette.middleware.base._CachedRequest object at 0x774df44eaa20>
call_next = <function BaseHTTPMiddleware.__call__.<locals>.call_next at 0x774df4388180>

    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        """Process the request through authentication."""
        path = request.url.path
        origin = request.headers.get("Origin", "*")
    
        # Allow CORS preflight requests through without auth
        if request.method == "OPTIONS":
            return await call_next(request)
    
        # Skip auth for public paths
        if _is_public_path(path):
            return await call_next(request)
    
        api_key = None
    
        # 1. Try Ticket Auth (Secure SSE)
        ticket = request.query_params.get("ticket")
        is_sse_path = any(p in path for p in ["/stream", "/events"])
    
        if ticket and is_sse_path:
            from src.core.auth.application.ticket_service import TicketService
    
            ticket_service = TicketService()
            try:
                # Redeem ticket (consume it)
                api_key = await ticket_service.redeem_ticket(ticket)
                if not api_key:
                    logger.warning(f"Invalid or expired ticket used for {path}")
                    return _cors_error_response(
                        401, "UNAUTHORIZED", "Invalid or expired ticket.", origin
                    )
            except Exception as e:
                logger.error(f"Ticket redemption error: {e}")
                return _cors_error_response(500, "INTERNAL_ERROR", "Auth error", origin)
            finally:
                await ticket_service.close()
    
        # 2. Try Standard Header Auth
        if not api_key:
            api_key = request.headers.get("X-API-Key")
    
        # 3. Fallback: Legacy Query Param for SSE (Deprecated but kept for compat if needed,
        #    but we prefer Ticket now. We can log a warning if used.)
        if not api_key and is_sse_path:
            api_key = request.query_params.get("api_key")
            if api_key:
                logger.warning(f"Legacy query param auth used for {path}. migrate to ticket auth.")
    
        if not api_key:
            logger.warning(f"Missing API key for {request.method} {path}")
            return _cors_error_response(
                401,
                "UNAUTHORIZED",
                "Missing API key. Provide X-API-Key header or valid ticket.",
                origin,
            )
    
        # Validate API key via Service
        from src.api.deps import _get_async_session_maker
        from src.core.admin_ops.application.api_key_service import ApiKeyService
    
        valid_key = None
        try:
            async with _get_async_session_maker()() as session:
                service = ApiKeyService(session)
                valid_key = await service.validate_key(api_key)
        except Exception as e:
            logger.error(f"Auth DB Error: {e}")
            return _cors_error_response(500, "INTERNAL_ERROR", "Authentication failed", origin)
    
        if not valid_key:
            logger.warning(f"Invalid API key {mask_api_key(api_key)} for {request.method} {path}")
            return _cors_error_response(401, "UNAUTHORIZED", "Invalid API key.", origin)
    
        # Resolve Tenant Context
        header_tenant_id = request.headers.get("X-Tenant-ID")
        allowed_tenants = {t.id for t in valid_key.tenants}
        tenant_id = None
    
        if header_tenant_id:
            # Client requested specific tenant
            if header_tenant_id in allowed_tenants:
                tenant_id = TenantId(header_tenant_id)
            elif "super_admin" in (valid_key.scopes or []) or "root" in (
                valid_key.scopes or []
            ):  # Allow Super Admin to impersonate any tenant
                tenant_id = TenantId(header_tenant_id)
            elif not allowed_tenants:
                # Legacy/Bootstrap: If key has no specific links, allow 'default' if requested
                # This ensures unmigrated keys still work for default tenant
                if header_tenant_id == "default":
                    tenant_id = TenantId("default")
                else:
                    logger.warning(
                        f"Access denied for key {valid_key.name} to tenant {header_tenant_id} (No links)"
                    )
                    return _cors_error_response(403, "FORBIDDEN", "Access to tenant denied", origin)
            else:
                logger.warning(
                    f"Access denied for key {valid_key.name} to tenant {header_tenant_id}"
                )
                return _cors_error_response(403, "FORBIDDEN", "Access to tenant denied", origin)
        else:
            # No tenant specified
            if len(allowed_tenants) == 1:
                # Ambiguity resolved: exact one match
                tenant_id = TenantId(list(allowed_tenants)[0])
            elif not allowed_tenants:
                # Fallback to default
                tenant_id = TenantId("default")
            else:
                # Ambiguous
                return _cors_error_response(
                    400,
                    "BAD_REQUEST",
                    "Multiple tenants available. Specify X-Tenant-ID header.",
                    origin,
                )
    
        permissions = valid_key.scopes or []
    
        set_current_tenant(tenant_id)
        set_permissions(permissions)
    
        # Resolve Tenant Role from the ApiKeyTenant association
        tenant_role = "user"  # Default role
        if str(tenant_id) in allowed_tenants:
            # Find the specific association to get the role
            from src.core.admin_ops.domain.api_key import ApiKeyTenant
    
            async with _get_async_session_maker()() as session:
                from sqlalchemy import select
    
                result = await session.execute(
                    select(ApiKeyTenant.role).where(
                        ApiKeyTenant.api_key_id == valid_key.id,
                        ApiKeyTenant.tenant_id == str(tenant_id),
                    )
                )
                role_row = result.scalar_one_or_none()
                if role_row:
                    tenant_role = role_row
    
        # Store in request state for easy access
        request.state.tenant_id = tenant_id
        request.state.permissions = permissions
        request.state.api_key_name = valid_key.name
        request.state.tenant_role = tenant_role
        request.state.is_super_admin = "super_admin" in permissions
    
        logger.debug(
            f"Authenticated: tenant={tenant_id}, key={valid_key.name}, "
            f"role={tenant_role}, super_admin={request.state.is_super_admin}, "
            f"path={request.method} {path}"
        )
    
>       return await call_next(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^

src/api/middleware/auth.py:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

request = <starlette.middleware.base._CachedRequest object at 0x774df44eaa20>

    async def call_next(request: Request) -> Response:
        async def receive_or_disconnect() -> Message:
            if response_sent.is_set():
                return {"type": "http.disconnect"}
    
            async with anyio.create_task_group() as task_group:
    
                async def wrap(func: Callable[[], Awaitable[T]]) -> T:
                    result = await func()
                    task_group.cancel_scope.cancel()
                    return result
    
                task_group.start_soon(wrap, response_sent.wait)
                message = await wrap(wrapped_receive)
    
            if response_sent.is_set():
                return {"type": "http.disconnect"}
    
            return message
    
        async def send_no_error(message: Message) -> None:
            try:
                await send_stream.send(message)
            except anyio.BrokenResourceError:
                # recv_stream has been closed, i.e. response_sent has been set.
                return
    
        async def coro() -> None:
            nonlocal app_exc
    
            with send_stream:
                try:
                    await self.app(scope, receive_or_disconnect, send_no_error)
                except Exception as exc:
                    app_exc = exc
    
        task_group.start_soon(coro)
    
        try:
            message = await recv_stream.receive()
            info = message.get("info", None)
            if message["type"] == "http.response.debug" and info is not None:
                message = await recv_stream.receive()
        except anyio.EndOfStream:
            if app_exc is not None:
                nonlocal exception_already_raised
                exception_already_raised = True
                # Prevent `anyio.EndOfStream` from polluting app exception context.
                # If both cause and context are None then the context is suppressed
                # and `anyio.EndOfStream` is not present in the exception traceback.
                # If exception cause is not None then it is propagated with
                # reraising here.
                # If exception has no cause but has context set then the context is
                # propagated as a cause with the reraise. This is necessary in order
                # to prevent `anyio.EndOfStream` from polluting the exception
                # context.
>               raise app_exc from app_exc.__cause__ or app_exc.__context__

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:168: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    async def coro() -> None:
        nonlocal app_exc
    
        with send_stream:
            try:
>               await self.app(scope, receive_or_disconnect, send_no_error)

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:144: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.api.middleware.rate_limit.UploadSizeLimitMiddleware object at 0x774df44bbe90>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774df4388d60>
send = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.send_no_error at 0x774df4389440>

    async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
        if scope["type"] != "http":
            await self.app(scope, receive, send)
            return
    
        request = _CachedRequest(scope, receive)
        wrapped_receive = request.wrapped_receive
        response_sent = anyio.Event()
        app_exc: Exception | None = None
        exception_already_raised = False
    
        async def call_next(request: Request) -> Response:
            async def receive_or_disconnect() -> Message:
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                async with anyio.create_task_group() as task_group:
    
                    async def wrap(func: Callable[[], Awaitable[T]]) -> T:
                        result = await func()
                        task_group.cancel_scope.cancel()
                        return result
    
                    task_group.start_soon(wrap, response_sent.wait)
                    message = await wrap(wrapped_receive)
    
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                return message
    
            async def send_no_error(message: Message) -> None:
                try:
                    await send_stream.send(message)
                except anyio.BrokenResourceError:
                    # recv_stream has been closed, i.e. response_sent has been set.
                    return
    
            async def coro() -> None:
                nonlocal app_exc
    
                with send_stream:
                    try:
                        await self.app(scope, receive_or_disconnect, send_no_error)
                    except Exception as exc:
                        app_exc = exc
    
            task_group.start_soon(coro)
    
            try:
                message = await recv_stream.receive()
                info = message.get("info", None)
                if message["type"] == "http.response.debug" and info is not None:
                    message = await recv_stream.receive()
            except anyio.EndOfStream:
                if app_exc is not None:
                    nonlocal exception_already_raised
                    exception_already_raised = True
                    # Prevent `anyio.EndOfStream` from polluting app exception context.
                    # If both cause and context are None then the context is suppressed
                    # and `anyio.EndOfStream` is not present in the exception traceback.
                    # If exception cause is not None then it is propagated with
                    # reraising here.
                    # If exception has no cause but has context set then the context is
                    # propagated as a cause with the reraise. This is necessary in order
                    # to prevent `anyio.EndOfStream` from polluting the exception
                    # context.
                    raise app_exc from app_exc.__cause__ or app_exc.__context__
                raise RuntimeError("No response returned.")
    
            assert message["type"] == "http.response.start"
    
            async def body_stream() -> BodyStreamGenerator:
                async for message in recv_stream:
                    if message["type"] == "http.response.pathsend":
                        yield message
                        break
                    assert message["type"] == "http.response.body", f"Unexpected message: {message}"
                    body = message.get("body", b"")
                    if body:
                        yield body
                    if not message.get("more_body", False):
                        break
    
            response = _StreamingResponse(status_code=message["status"], content=body_stream(), info=info)
            response.raw_headers = message["headers"]
            return response
    
        streams: anyio.create_memory_object_stream[Message] = anyio.create_memory_object_stream()
        send_stream, recv_stream = streams
>       with recv_stream, send_stream, collapse_excgroups():

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:191: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <contextlib._GeneratorContextManager object at 0x774df4398710>
typ = <class 'ExceptionGroup'>
value = ExceptionGroup('unhandled errors in a TaskGroup', [RuntimeError('Task dispatch failed: Retry in 60s: RuntimeError(\'Ex...not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies\\\'}\')')])
traceback = <traceback object at 0x774df4050980>

    def __exit__(self, typ, value, traceback):
        if typ is None:
            try:
                next(self.gen)
            except StopIteration:
                return False
            else:
                try:
                    raise RuntimeError("generator didn't stop")
                finally:
                    self.gen.close()
        else:
            if value is None:
                # Need to force instantiation so we can reliably
                # tell if we get the same exception back
                value = typ()
            try:
>               self.gen.throw(value)

/usr/lib/python3.12/contextlib.py:158: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @contextmanager
    def collapse_excgroups() -> Generator[None, None, None]:
        try:
            yield
        except BaseException as exc:
            if has_exceptiongroups:  # pragma: no cover
                while isinstance(exc, BaseExceptionGroup) and len(exc.exceptions) == 1:
                    exc = exc.exceptions[0]
    
>           raise exc

.venv/lib/python3.12/site-packages/starlette/_utils.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.api.middleware.rate_limit.UploadSizeLimitMiddleware object at 0x774df44bbe90>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774df4388d60>
send = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.send_no_error at 0x774df4389440>

    async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
        if scope["type"] != "http":
            await self.app(scope, receive, send)
            return
    
        request = _CachedRequest(scope, receive)
        wrapped_receive = request.wrapped_receive
        response_sent = anyio.Event()
        app_exc: Exception | None = None
        exception_already_raised = False
    
        async def call_next(request: Request) -> Response:
            async def receive_or_disconnect() -> Message:
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                async with anyio.create_task_group() as task_group:
    
                    async def wrap(func: Callable[[], Awaitable[T]]) -> T:
                        result = await func()
                        task_group.cancel_scope.cancel()
                        return result
    
                    task_group.start_soon(wrap, response_sent.wait)
                    message = await wrap(wrapped_receive)
    
                if response_sent.is_set():
                    return {"type": "http.disconnect"}
    
                return message
    
            async def send_no_error(message: Message) -> None:
                try:
                    await send_stream.send(message)
                except anyio.BrokenResourceError:
                    # recv_stream has been closed, i.e. response_sent has been set.
                    return
    
            async def coro() -> None:
                nonlocal app_exc
    
                with send_stream:
                    try:
                        await self.app(scope, receive_or_disconnect, send_no_error)
                    except Exception as exc:
                        app_exc = exc
    
            task_group.start_soon(coro)
    
            try:
                message = await recv_stream.receive()
                info = message.get("info", None)
                if message["type"] == "http.response.debug" and info is not None:
                    message = await recv_stream.receive()
            except anyio.EndOfStream:
                if app_exc is not None:
                    nonlocal exception_already_raised
                    exception_already_raised = True
                    # Prevent `anyio.EndOfStream` from polluting app exception context.
                    # If both cause and context are None then the context is suppressed
                    # and `anyio.EndOfStream` is not present in the exception traceback.
                    # If exception cause is not None then it is propagated with
                    # reraising here.
                    # If exception has no cause but has context set then the context is
                    # propagated as a cause with the reraise. This is necessary in order
                    # to prevent `anyio.EndOfStream` from polluting the exception
                    # context.
                    raise app_exc from app_exc.__cause__ or app_exc.__context__
                raise RuntimeError("No response returned.")
    
            assert message["type"] == "http.response.start"
    
            async def body_stream() -> BodyStreamGenerator:
                async for message in recv_stream:
                    if message["type"] == "http.response.pathsend":
                        yield message
                        break
                    assert message["type"] == "http.response.body", f"Unexpected message: {message}"
                    body = message.get("body", b"")
                    if body:
                        yield body
                    if not message.get("more_body", False):
                        break
    
            response = _StreamingResponse(status_code=message["status"], content=body_stream(), info=info)
            response.raw_headers = message["headers"]
            return response
    
        streams: anyio.create_memory_object_stream[Message] = anyio.create_memory_object_stream()
        send_stream, recv_stream = streams
        with recv_stream, send_stream, collapse_excgroups():
            async with anyio.create_task_group() as task_group:
>               response = await self.dispatch_func(request, call_next)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:193: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.api.middleware.rate_limit.UploadSizeLimitMiddleware object at 0x774df44bbe90>
request = <starlette.middleware.base._CachedRequest object at 0x774df4367b30>
call_next = <function BaseHTTPMiddleware.__call__.<locals>.call_next at 0x774df44e3240>

    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        """Process the request through size limiting."""
        origin = request.headers.get("Origin", "*")
    
        # Only check POST/PUT requests
        if request.method not in ("POST", "PUT", "PATCH"):
            return await call_next(request)
    
        content_length = request.headers.get("content-length")
        if content_length:
            try:
                size_bytes = int(content_length)
                max_bytes = settings.uploads.max_size_mb * 1024 * 1024
    
                if size_bytes > max_bytes:
                    logger.warning(
                        f"Upload too large: {size_bytes} bytes > {max_bytes} bytes "
                        f"(path={request.method} {request.url.path})"
                    )
                    response = JSONResponse(
                        status_code=413,
                        content={
                            "error": {
                                "code": "PAYLOAD_TOO_LARGE",
                                "message": f"Upload exceeds maximum size of {settings.uploads.max_size_mb}MB",
                                "max_size_mb": settings.uploads.max_size_mb,
                                "received_mb": round(size_bytes / (1024 * 1024), 2),
                            }
                        },
                    )
                    return _add_cors_headers(response, origin)
            except ValueError:
                pass  # Invalid content-length, let FastAPI handle it
    
>       return await call_next(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^

src/api/middleware/rate_limit.py:187: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

request = <starlette.middleware.base._CachedRequest object at 0x774df4367b30>

    async def call_next(request: Request) -> Response:
        async def receive_or_disconnect() -> Message:
            if response_sent.is_set():
                return {"type": "http.disconnect"}
    
            async with anyio.create_task_group() as task_group:
    
                async def wrap(func: Callable[[], Awaitable[T]]) -> T:
                    result = await func()
                    task_group.cancel_scope.cancel()
                    return result
    
                task_group.start_soon(wrap, response_sent.wait)
                message = await wrap(wrapped_receive)
    
            if response_sent.is_set():
                return {"type": "http.disconnect"}
    
            return message
    
        async def send_no_error(message: Message) -> None:
            try:
                await send_stream.send(message)
            except anyio.BrokenResourceError:
                # recv_stream has been closed, i.e. response_sent has been set.
                return
    
        async def coro() -> None:
            nonlocal app_exc
    
            with send_stream:
                try:
                    await self.app(scope, receive_or_disconnect, send_no_error)
                except Exception as exc:
                    app_exc = exc
    
        task_group.start_soon(coro)
    
        try:
            message = await recv_stream.receive()
            info = message.get("info", None)
            if message["type"] == "http.response.debug" and info is not None:
                message = await recv_stream.receive()
        except anyio.EndOfStream:
            if app_exc is not None:
                nonlocal exception_already_raised
                exception_already_raised = True
                # Prevent `anyio.EndOfStream` from polluting app exception context.
                # If both cause and context are None then the context is suppressed
                # and `anyio.EndOfStream` is not present in the exception traceback.
                # If exception cause is not None then it is propagated with
                # reraising here.
                # If exception has no cause but has context set then the context is
                # propagated as a cause with the reraise. This is necessary in order
                # to prevent `anyio.EndOfStream` from polluting the exception
                # context.
>               raise app_exc from app_exc.__cause__ or app_exc.__context__

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:168: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    async def coro() -> None:
        nonlocal app_exc
    
        with send_stream:
            try:
>               await self.app(scope, receive_or_disconnect, send_no_error)

.venv/lib/python3.12/site-packages/starlette/middleware/base.py:144: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <starlette.middleware.cors.CORSMiddleware object at 0x774df44bbb30>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774df4388360>
send = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.send_no_error at 0x774df4388220>

    async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
        if scope["type"] != "http":  # pragma: no cover
            await self.app(scope, receive, send)
            return
    
        method = scope["method"]
        headers = Headers(scope=scope)
        origin = headers.get("origin")
    
        if origin is None:
>           await self.app(scope, receive, send)

.venv/lib/python3.12/site-packages/starlette/middleware/cors.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <starlette.middleware.exceptions.ExceptionMiddleware object at 0x774df44bb980>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774df4388360>
send = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.send_no_error at 0x774df4388220>

    async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
        if scope["type"] not in ("http", "websocket"):
            await self.app(scope, receive, send)
            return
    
        scope["starlette.exception_handlers"] = (
            self._exception_handlers,
            self._status_handlers,
        )
    
        conn: Request | WebSocket
        if scope["type"] == "http":
            conn = Request(scope, receive, send)
        else:
            conn = WebSocket(scope, receive, send)
    
>       await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)

.venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py:63: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774df4388360>
send = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.send_no_error at 0x774df4388220>

    async def wrapped_app(scope: Scope, receive: Receive, send: Send) -> None:
        response_started = False
    
        async def sender(message: Message) -> None:
            nonlocal response_started
    
            if message["type"] == "http.response.start":
                response_started = True
            await send(message)
    
        try:
            await app(scope, receive, sender)
        except Exception as exc:
            handler = None
    
            if isinstance(exc, HTTPException):
                handler = status_handlers.get(exc.status_code)
    
            if handler is None:
                handler = _lookup_exception_handler(exception_handlers, exc)
    
            if handler is None:
>               raise exc

.venv/lib/python3.12/site-packages/starlette/_exception_handler.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774df4388360>
send = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.send_no_error at 0x774df4388220>

    async def wrapped_app(scope: Scope, receive: Receive, send: Send) -> None:
        response_started = False
    
        async def sender(message: Message) -> None:
            nonlocal response_started
    
            if message["type"] == "http.response.start":
                response_started = True
            await send(message)
    
        try:
>           await app(scope, receive, sender)

.venv/lib/python3.12/site-packages/starlette/_exception_handler.py:42: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <fastapi.middleware.asyncexitstack.AsyncExitStackMiddleware object at 0x774df44bb7d0>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774df4388360>
send = <function wrap_app_handling_exceptions.<locals>.wrapped_app.<locals>.sender at 0x774df43894e0>

    async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
        async with AsyncExitStack() as stack:
            scope[self.context_name] = stack
>           await self.app(scope, receive, send)

.venv/lib/python3.12/site-packages/fastapi/middleware/asyncexitstack.py:18: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <fastapi.routing.APIRouter object at 0x774e29e78740>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774df4388360>
send = <function wrap_app_handling_exceptions.<locals>.wrapped_app.<locals>.sender at 0x774df43894e0>

    async def __call__(self, scope: Scope, receive: Receive, send: Send) -> None:
        """
        The main entry point to the Router class.
        """
>       await self.middleware_stack(scope, receive, send)

.venv/lib/python3.12/site-packages/starlette/routing.py:716: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <fastapi.routing.APIRouter object at 0x774e29e78740>
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774df4388360>
send = <function wrap_app_handling_exceptions.<locals>.wrapped_app.<locals>.sender at 0x774df43894e0>

    async def app(self, scope: Scope, receive: Receive, send: Send) -> None:
        assert scope["type"] in ("http", "websocket", "lifespan")
    
        if "router" not in scope:
            scope["router"] = self
    
        if scope["type"] == "lifespan":
            await self.lifespan(scope, receive, send)
            return
    
        partial = None
    
        for route in self.routes:
            # Determine if any route matches the incoming scope,
            # and hand over to the matching route if found.
            match, child_scope = route.matches(scope)
            if match == Match.FULL:
                scope.update(child_scope)
>               await route.handle(scope, receive, send)

.venv/lib/python3.12/site-packages/starlette/routing.py:736: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = APIRoute(path='/v1/documents', name='upload_document', methods=['POST'])
scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774df4388360>
send = <function wrap_app_handling_exceptions.<locals>.wrapped_app.<locals>.sender at 0x774df43894e0>

    async def handle(self, scope: Scope, receive: Receive, send: Send) -> None:
        if self.methods and scope["method"] not in self.methods:
            headers = {"Allow": ", ".join(self.methods)}
            if "app" in scope:
                raise HTTPException(status_code=405, headers=headers)
            else:
                response = PlainTextResponse("Method Not Allowed", status_code=405, headers=headers)
            await response(scope, receive, send)
        else:
>           await self.app(scope, receive, send)

.venv/lib/python3.12/site-packages/starlette/routing.py:290: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774df4388360>
send = <function wrap_app_handling_exceptions.<locals>.wrapped_app.<locals>.sender at 0x774df43894e0>

    async def app(scope: Scope, receive: Receive, send: Send) -> None:
        request = Request(scope, receive, send)
    
        async def app(scope: Scope, receive: Receive, send: Send) -> None:
            # Starts customization
            response_awaited = False
            async with AsyncExitStack() as request_stack:
                scope["fastapi_inner_astack"] = request_stack
                async with AsyncExitStack() as function_stack:
                    scope["fastapi_function_astack"] = function_stack
                    response = await f(request)
                await response(scope, receive, send)
                # Continues customization
                response_awaited = True
            if not response_awaited:
                raise FastAPIError(
                    "Response not awaited. There's a high chance that the "
                    "application code is raising an exception and a dependency with yield "
                    "has a block with a bare except, or a block with except Exception, "
                    "and is not raising the exception again. Read more about it in the "
                    "docs: https://fastapi.tiangolo.com/tutorial/dependencies/dependencies-with-yield/#dependencies-with-yield-and-except"
                )
    
        # Same as in Starlette
>       await wrap_app_handling_exceptions(app, request)(scope, receive, send)

.venv/lib/python3.12/site-packages/fastapi/routing.py:115: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774df4388360>
send = <function wrap_app_handling_exceptions.<locals>.wrapped_app.<locals>.sender at 0x774df43894e0>

    async def wrapped_app(scope: Scope, receive: Receive, send: Send) -> None:
        response_started = False
    
        async def sender(message: Message) -> None:
            nonlocal response_started
    
            if message["type"] == "http.response.start":
                response_started = True
            await send(message)
    
        try:
            await app(scope, receive, sender)
        except Exception as exc:
            handler = None
    
            if isinstance(exc, HTTPException):
                handler = status_handlers.get(exc.status_code)
    
            if handler is None:
                handler = _lookup_exception_handler(exception_handlers, exc)
    
            if handler is None:
>               raise exc

.venv/lib/python3.12/site-packages/starlette/_exception_handler.py:53: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774df4388360>
send = <function wrap_app_handling_exceptions.<locals>.wrapped_app.<locals>.sender at 0x774df43894e0>

    async def wrapped_app(scope: Scope, receive: Receive, send: Send) -> None:
        response_started = False
    
        async def sender(message: Message) -> None:
            nonlocal response_started
    
            if message["type"] == "http.response.start":
                response_started = True
            await send(message)
    
        try:
>           await app(scope, receive, sender)

.venv/lib/python3.12/site-packages/starlette/_exception_handler.py:42: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

scope = {'app': <fastapi.applications.FastAPI object at 0x774e29e78650>, 'asgi': {'version': '3.0'}, 'client': ('127.0.0.1', 123), 'endpoint': <function upload_document at 0x774e29ec8040>, ...}
receive = <function BaseHTTPMiddleware.__call__.<locals>.call_next.<locals>.receive_or_disconnect at 0x774df4388360>
send = <function wrap_app_handling_exceptions.<locals>.wrapped_app.<locals>.sender at 0x774df4389300>

    async def app(scope: Scope, receive: Receive, send: Send) -> None:
        # Starts customization
        response_awaited = False
        async with AsyncExitStack() as request_stack:
            scope["fastapi_inner_astack"] = request_stack
            async with AsyncExitStack() as function_stack:
                scope["fastapi_function_astack"] = function_stack
>               response = await f(request)
                           ^^^^^^^^^^^^^^^^

.venv/lib/python3.12/site-packages/fastapi/routing.py:101: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

request = <starlette.requests.Request object at 0x774df43994f0>

    async def app(request: Request) -> Response:
        response: Union[Response, None] = None
        file_stack = request.scope.get("fastapi_middleware_astack")
        assert isinstance(file_stack, AsyncExitStack), (
            "fastapi_middleware_astack not found in request scope"
        )
    
        # Extract endpoint context for error messages
        endpoint_ctx = (
            _extract_endpoint_context(dependant.call)
            if dependant.call
            else EndpointContext()
        )
    
        if dependant.path:
            # For mounted sub-apps, include the mount path prefix
            mount_path = request.scope.get("root_path", "").rstrip("/")
            endpoint_ctx["path"] = f"{request.method} {mount_path}{dependant.path}"
    
        # Read body and auto-close files
        try:
            body: Any = None
            if body_field:
                if is_body_form:
                    body = await request.form()
                    file_stack.push_async_callback(body.close)
                else:
                    body_bytes = await request.body()
                    if body_bytes:
                        json_body: Any = Undefined
                        content_type_value = request.headers.get("content-type")
                        if not content_type_value:
                            json_body = await request.json()
                        else:
                            message = email.message.Message()
                            message["content-type"] = content_type_value
                            if message.get_content_maintype() == "application":
                                subtype = message.get_content_subtype()
                                if subtype == "json" or subtype.endswith("+json"):
                                    json_body = await request.json()
                        if json_body != Undefined:
                            body = json_body
                        else:
                            body = body_bytes
        except json.JSONDecodeError as e:
            validation_error = RequestValidationError(
                [
                    {
                        "type": "json_invalid",
                        "loc": ("body", e.pos),
                        "msg": "JSON decode error",
                        "input": {},
                        "ctx": {"error": e.msg},
                    }
                ],
                body=e.doc,
                endpoint_ctx=endpoint_ctx,
            )
            raise validation_error from e
        except HTTPException:
            # If a middleware raises an HTTPException, it should be raised again
            raise
        except Exception as e:
            http_error = HTTPException(
                status_code=400, detail="There was an error parsing the body"
            )
            raise http_error from e
    
        # Solve dependencies and run path operation function, auto-closing dependencies
        errors: list[Any] = []
        async_exit_stack = request.scope.get("fastapi_inner_astack")
        assert isinstance(async_exit_stack, AsyncExitStack), (
            "fastapi_inner_astack not found in request scope"
        )
        solved_result = await solve_dependencies(
            request=request,
            dependant=dependant,
            body=body,
            dependency_overrides_provider=dependency_overrides_provider,
            async_exit_stack=async_exit_stack,
            embed_body_fields=embed_body_fields,
        )
        errors = solved_result.errors
        if not errors:
>           raw_response = await run_endpoint_function(
                dependant=dependant,
                values=solved_result.values,
                is_coroutine=is_coroutine,
            )

.venv/lib/python3.12/site-packages/fastapi/routing.py:355: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    async def run_endpoint_function(
        *, dependant: Dependant, values: dict[str, Any], is_coroutine: bool
    ) -> Any:
        # Only called by get_request_handler. Has been split into its own function to
        # facilitate profiling endpoints, since inner functions are harder to profile.
        assert dependant.call is not None, "dependant.call must be a function"
    
        if is_coroutine:
>           return await dependant.call(**values)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.venv/lib/python3.12/site-packages/fastapi/routing.py:243: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

request = <starlette.requests.Request object at 0x774df43994f0>
file = UploadFile(filename='test_integration_8e4383ed.pdf', size=1244, headers=Headers({'content-disposition': 'form-data; name="file"; filename="test_integration_8e4383ed.pdf"', 'content-type': 'application/pdf'}))
tenant_id = None
session = <sqlalchemy.ext.asyncio.session.AsyncSession object at 0x774df439aa80>

    @router.post(
        "",
        status_code=status.HTTP_202_ACCEPTED,
        response_model=DocumentUploadResponse,
        summary="Upload Document",
        description="""
        Upload a document for ingestion into the knowledge base.
    
        Returns 202 Accepted immediately with a document ID.
        Use the events_url to monitor processing progress via SSE.
        """,
    )
    async def upload_document(
        request: Request,
        file: UploadFile = File(..., description="Document file to upload"),
        tenant_id: str = Form(default=None, description="Tenant ID (optional, super admin only)"),
        session: AsyncSession = Depends(get_db_session),
    ) -> DocumentUploadResponse:
        """
        Upload a document for async ingestion.
        """
        from src.core.ingestion.application.use_cases_documents import UploadDocumentRequest
    
        # Resolve Tenant
        permissions = getattr(request.state, "permissions", [])
        is_super_admin = "super_admin" in permissions
    
        target_tenant_id = None
        if is_super_admin and tenant_id:
            target_tenant_id = tenant_id
        else:
            target_tenant_id = _get_tenant_id(request)
    
        # Read file content
        content = await file.read()
    
        # Build use case with dependencies
        from src.amber_platform.composition_root import build_upload_document_use_case
    
        max_size = settings.uploads.max_size_mb * 1024 * 1024
        use_case = build_upload_document_use_case(session=session, max_size_bytes=max_size)
    
        # Execute use case
        try:
>           result = await use_case.execute(
                UploadDocumentRequest(
                    tenant_id=target_tenant_id,
                    filename=file.filename or "unnamed",
                    content=content,
                    content_type=file.content_type or "application/octet-stream",
                )
            )

src/api/routes/documents.py:151: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.core.ingestion.application.use_cases_documents.UploadDocumentUseCase object at 0x774df40af2c0>
request = UploadDocumentRequest(tenant_id='integration_test_tenant', filename='test_integration_8e4383ed.pdf', content=b'%PDF-1....ze 6\n/Root 1 0 R\n>>\nstartxref\n882\n%%EOF\n\n% Random: 8e4383ed 1771003132.0675614', content_type='application/pdf')

    async def execute(self, request: UploadDocumentRequest) -> UploadDocumentResult:
        """
        Execute the document upload use case.
    
        Args:
            request: Upload request with tenant, filename, content.
    
        Returns:
            UploadDocumentResult with document_id and status.
    
        Raises:
            ValueError: If file is empty or too large.
        """
        # Validate file size
        if len(request.content) == 0:
            raise ValueError("Empty file uploaded")
    
        if len(request.content) > self._max_size_bytes:
            max_mb = self._max_size_bytes // (1024 * 1024)
            raise ValueError(f"File too large. Max size: {max_mb}MB")
    
        # Register document
        from src.core.ingestion.application.ingestion_service import IngestionService
        from src.core.state.machine import DocumentStatus
    
        service = IngestionService(
            document_repository=self._document_repository,
            tenant_repository=self._tenant_repository,
            unit_of_work=self._unit_of_work,
            storage_client=self._storage,
            neo4j_client=self._graph_client,
            vector_store=self._vector_store,
            vector_store_factory=self._vector_store_factory,
            event_dispatcher=self._event_dispatcher,
        )
        document = await service.register_document(
            tenant_id=request.tenant_id,
            filename=request.filename,
            file_content=request.content,
            content_type=request.content_type,
        )
    
        # Commit transaction before dispatching async processing
        await self._unit_of_work.commit()
    
        # Dispatch async processing if new document
        is_duplicate = document.status != DocumentStatus.INGESTED
        if not is_duplicate:
            if self._task_dispatcher:
>               await self._task_dispatcher.dispatch(
                    "src.workers.tasks.process_document", args=[document.id, request.tenant_id]
                )

src/core/ingestion/application/use_cases_documents.py:154: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <src.infrastructure.adapters.celery_dispatcher.CeleryTaskDispatcher object at 0x774df439b4a0>
task_name = 'src.workers.tasks.process_document'
args = ['doc_174218dbffc2a138', 'integration_test_tenant'], kwargs = {}

    async def dispatch(
        self, task_name: str, args: list[Any] | None = None, kwargs: dict[str, Any] | None = None
    ) -> str:
        args = args or []
        kwargs = kwargs or {}
    
        try:
            # We assume task_name matches the registered Celery task name string
            # OR we can map specific domain names to celery function names here if we want strict decoupling.
            # For simplicity, we assume strict naming.
    
            # Note: Celery send_task is synchronous unless we use its async API (rarely used).
            # Usually send_task is fast enough (push to Redis).
            # Check for eager execution
            if celery_app.conf.task_always_eager:
                if task_name in celery_app.tasks:
                    task = celery_app.tasks[task_name]
                    result = task.apply(args=args, kwargs=kwargs)
                    return str(result.id)
                else:
                    logger.warning(
                        f"Task {task_name} not found in registry for eager execution. Falling back to send_task."
                    )
    
            result = celery_app.send_task(task_name, args=args, kwargs=kwargs)
            return str(result.id)
        except Exception as e:
            logger.error(f"Failed to dispatch task {task_name}: {e}")
>           raise RuntimeError(f"Task dispatch failed: {e}") from e
E           RuntimeError: Task dispatch failed: Retry in 60s: RuntimeError('Extraction failed after checking 1 tools. Details: {\'unstructured\': \'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies\'}')

src/infrastructure/adapters/celery_dispatcher.py:50: RuntimeError
---------------------------- Captured stdout setup -----------------------------
{"timestamp": "2026-02-13 18:18:46,405", "level": "INFO", "message": "Connected to Neo4j at bolt://localhost:7687", "module": "neo4j_client", "function": "connect", "line": 55}
{"timestamp": "2026-02-13 18:18:47,056", "level": "INFO", "message": "Connected to Milvus at localhost:19530", "module": "milvus", "function": "connect", "line": 158}
{"timestamp": "2026-02-13 18:18:48,173", "level": "INFO", "message": "Deleted 0 chunks for tenant integration_test_tenant", "module": "milvus", "function": "delete_by_tenant", "line": 599}
{"timestamp": "2026-02-13 18:18:48,176", "level": "INFO", "message": "Creating collection: amber_integration_test_tenant", "module": "milvus", "function": "_create_collection", "line": 169}
{"timestamp": "2026-02-13 18:18:50,671", "level": "INFO", "message": "Collection amber_integration_test_tenant created with HNSW index and Dynamic Fields", "module": "milvus", "function": "_create_collection", "line": 259}
{"timestamp": "2026-02-13 18:18:50,671", "level": "INFO", "message": "Connected to Milvus at localhost:19530", "module": "milvus", "function": "connect", "line": 158}
{"timestamp": "2026-02-13 18:18:50,679", "level": "WARNING", "message": "Dropped collection amber_integration_test_tenant", "module": "milvus", "function": "drop_collection", "line": 798}
Consider using the pymupdf_layout package for a greatly improved page layout analysis.
------------------------------ Captured log setup ------------------------------
INFO     src.core.graph.infrastructure.neo4j_client:neo4j_client.py:55 Connected to Neo4j at bolt://localhost:7687
INFO     src.core.retrieval.infrastructure.vector_store.milvus:milvus.py:158 Connected to Milvus at localhost:19530
INFO     src.core.retrieval.infrastructure.vector_store.milvus:milvus.py:599 Deleted 0 chunks for tenant integration_test_tenant
INFO     src.core.retrieval.infrastructure.vector_store.milvus:milvus.py:169 Creating collection: amber_integration_test_tenant
INFO     src.core.retrieval.infrastructure.vector_store.milvus:milvus.py:259 Collection amber_integration_test_tenant created with HNSW index and Dynamic Fields
INFO     src.core.retrieval.infrastructure.vector_store.milvus:milvus.py:158 Connected to Milvus at localhost:19530
WARNING  src.core.retrieval.infrastructure.vector_store.milvus:milvus.py:798 Dropped collection amber_integration_test_tenant
----------------------------- Captured stdout call -----------------------------

0. Pipeline running under tenant isolation.

1. Uploading document...
{"timestamp": "2026-02-13 18:18:52,213", "level": "INFO", "message": "State Change [Doc: doc_174218dbffc2a138] None -> ingested", "module": "dispatcher", "function": "emit_state_change", "line": 44, "request_id": "req_a0be8aae8a314ea28a7b79f4bcef20c1"}
{"timestamp": "2026-02-13 18:18:52,215", "level": "INFO", "message": "Registered new document: test_integration_8e4383ed.pdf (ID: doc_174218dbffc2a138)", "module": "ingestion_service", "function": "register_document", "line": 171, "request_id": "req_a0be8aae8a314ea28a7b79f4bcef20c1"}
{"timestamp": "2026-02-13 18:18:52,221", "level": "INFO", "message": "[Task d1996ea6-b6f0-4702-b19a-bf1ad6a1aa12] Starting processing for document doc_174218dbffc2a138", "module": "tasks", "function": "process_document", "line": 141, "request_id": "req_a0be8aae8a314ea28a7b79f4bcef20c1"}
{"timestamp": "2026-02-13 18:18:52,222", "level": "INFO", "message": "Executing deep reset of singletons for background task isolation", "module": "tasks", "function": "deep_reset_singletons", "line": 363}
{"timestamp": "2026-02-13 18:18:52,223", "level": "INFO", "message": "Platform registry singletons reset.", "module": "tasks", "function": "deep_reset_singletons", "line": 413}
{"timestamp": "2026-02-13 18:18:52,308", "level": "INFO", "message": "DEBUG: MinIO Fetching integration_test_tenant/doc_174218dbffc2a138/test_integration_8e4383ed.pdf from documents", "module": "storage_client", "function": "get_file", "line": 123}
{"timestamp": "2026-02-13 18:18:52,316", "level": "INFO", "message": "Attempting extraction with unstructured for test_integration_8e4383ed.pdf", "module": "fallback", "function": "extract_with_fallback", "line": 39}
{"timestamp": "2026-02-13 18:18:52,317", "level": "ERROR", "message": "Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install \"unstructured[pdf]\" (including quotes) to install the required dependencies", "module": "unstructured_extractor", "function": "extract", "line": 86}
{"timestamp": "2026-02-13 18:18:52,317", "level": "WARNING", "message": "Extractor unstructured failed for test_integration_8e4383ed.pdf: Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install \"unstructured[pdf]\" (including quotes) to install the required dependencies", "module": "fallback", "function": "extract_with_fallback", "line": 42}
{"timestamp": "2026-02-13 18:18:52,317", "level": "ERROR", "message": "All extractors failed for test_integration_8e4383ed.pdf. Errors: {'unstructured': 'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install \"unstructured[pdf]\" (including quotes) to install the required dependencies'}", "module": "fallback", "function": "extract_with_fallback", "line": 47}
{"timestamp": "2026-02-13 18:18:52,317", "level": "ERROR", "message": "Failed to process document doc_174218dbffc2a138", "module": "ingestion_service", "function": "process_document", "line": 696, "exception": "Traceback (most recent call last):\n  File \"/home/daniele/Amber_2.0/src/core/ingestion/application/ingestion_service.py\", line 233, in process_document\n    extraction_result = await extractor.extract(\n                        ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/core/ingestion/infrastructure/extraction/fallback_extractor.py\", line 9, in extract\n    result = await FallbackManager.extract_with_fallback(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/core/ingestion/infrastructure/extraction/fallback.py\", line 48, in extract_with_fallback\n    raise RuntimeError(\nRuntimeError: Extraction failed after checking 1 tools. Details: {'unstructured': 'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install \"unstructured[pdf]\" (including quotes) to install the required dependencies'}"}
{"timestamp": "2026-02-13 18:18:52,334", "level": "ERROR", "message": "[Task d1996ea6-b6f0-4702-b19a-bf1ad6a1aa12] Failed processing document doc_174218dbffc2a138: Extraction failed after checking 1 tools. Details: {'unstructured': 'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install \"unstructured[pdf]\" (including quotes) to install the required dependencies'}\nTraceback (most recent call last):\n  File \"/home/daniele/Amber_2.0/src/workers/tasks.py\", line 144, in process_document\n    result = run_async(_process_document_async(document_id, tenant_id, self.request.id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/workers/tasks.py\", line 76, in run_async\n    res = future.result()\n          ^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 456, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/usr/lib/python3.12/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/workers/tasks.py\", line 67, in runner\n    res = asyncio.run(coro)\n          ^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/asyncio/runners.py\", line 194, in run\n    return runner.run(main)\n           ^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/asyncio/runners.py\", line 118, in run\n    return self._loop.run_until_complete(task)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 687, in run_until_complete\n    return future.result()\n           ^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/workers/tasks.py\", line 541, in _process_document_async\n    await service.process_document(document_id)\n  File \"/home/daniele/Amber_2.0/src/core/ingestion/application/ingestion_service.py\", line 233, in process_document\n    extraction_result = await extractor.extract(\n                        ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/core/ingestion/infrastructure/extraction/fallback_extractor.py\", line 9, in extract\n    result = await FallbackManager.extract_with_fallback(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/core/ingestion/infrastructure/extraction/fallback.py\", line 48, in extract_with_fallback\n    raise RuntimeError(\nRuntimeError: Extraction failed after checking 1 tools. Details: {'unstructured': 'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install \"unstructured[pdf]\" (including quotes) to install the required dependencies'}\n", "module": "tasks", "function": "process_document", "line": 161, "request_id": "req_a0be8aae8a314ea28a7b79f4bcef20c1"}
{"timestamp": "2026-02-13 18:18:52,570", "level": "ERROR", "message": "Failed to dispatch task src.workers.tasks.process_document: Retry in 60s: RuntimeError('Extraction failed after checking 1 tools. Details: {\\'unstructured\\': \\'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install \"unstructured[pdf]\" (including quotes) to install the required dependencies\\'}')", "module": "celery_dispatcher", "function": "dispatch", "line": 49, "request_id": "req_a0be8aae8a314ea28a7b79f4bcef20c1"}
{"timestamp": "2026-02-13 18:18:52,571", "level": "ERROR", "message": "Request exception: Task dispatch failed: Retry in 60s: RuntimeError('Extraction failed after checking 1 tools. Details: {\\'unstructured\\': \\'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install \"unstructured[pdf]\" (including quotes) to install the required dependencies\\'}')", "module": "middleware", "function": "dispatch", "line": 85, "request_id": "req_a0be8aae8a314ea28a7b79f4bcef20c1", "method": "POST", "path": "/v1/documents", "status_code": 500, "latency_ms": 501.52}
{"timestamp": "2026-02-13 18:18:52,572", "level": "ERROR", "message": "Unhandled exception: RuntimeError: Task dispatch failed: Retry in 60s: RuntimeError('Extraction failed after checking 1 tools. Details: {\\'unstructured\\': \\'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install \"unstructured[pdf]\" (including quotes) to install the required dependencies\\'}')", "module": "exceptions", "function": "unhandled_exception_handler", "line": 123, "request_id": "req_a0be8aae8a314ea28a7b79f4bcef20c1", "exception": "Traceback (most recent call last):\n  File \"/home/daniele/Amber_2.0/src/workers/tasks.py\", line 144, in process_document\n    result = run_async(_process_document_async(document_id, tenant_id, self.request.id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/workers/tasks.py\", line 76, in run_async\n    res = future.result()\n          ^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 456, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/usr/lib/python3.12/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/workers/tasks.py\", line 67, in runner\n    res = asyncio.run(coro)\n          ^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/asyncio/runners.py\", line 194, in run\n    return runner.run(main)\n           ^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/asyncio/runners.py\", line 118, in run\n    return self._loop.run_until_complete(task)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 687, in run_until_complete\n    return future.result()\n           ^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/workers/tasks.py\", line 541, in _process_document_async\n    await service.process_document(document_id)\n  File \"/home/daniele/Amber_2.0/src/core/ingestion/application/ingestion_service.py\", line 233, in process_document\n    extraction_result = await extractor.extract(\n                        ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/core/ingestion/infrastructure/extraction/fallback_extractor.py\", line 9, in extract\n    result = await FallbackManager.extract_with_fallback(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/core/ingestion/infrastructure/extraction/fallback.py\", line 48, in extract_with_fallback\n    raise RuntimeError(\nRuntimeError: Extraction failed after checking 1 tools. Details: {'unstructured': 'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install \"unstructured[pdf]\" (including quotes) to install the required dependencies'}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/daniele/Amber_2.0/src/infrastructure/adapters/celery_dispatcher.py\", line 39, in dispatch\n    result = task.apply(args=args, kwargs=kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/celery/app/task.py\", line 843, in apply\n    ret = tracer(task_id, args, kwargs, request)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/celery/app/trace.py\", line 494, in trace_task\n    I, R, state, retval = on_error(\n                          ^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/celery/app/trace.py\", line 479, in trace_task\n    R = retval = fun(*args, **kwargs)\n                 ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/celery/app/autoretry.py\", line 38, in run\n    return task._orig_run(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/workers/tasks.py\", line 173, in process_document\n    raise self.retry(exc=e)\n          ^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/celery/app/task.py\", line 763, in retry\n    raise ret\ncelery.exceptions.Retry: Retry in 60s: RuntimeError('Extraction failed after checking 1 tools. Details: {\\'unstructured\\': \\'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install \"unstructured[pdf]\" (including quotes) to install the required dependencies\\'}')\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/errors.py\", line 164, in __call__\n    await self.app(scope, receive, _send)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 191, in __call__\n    with recv_stream, send_stream, collapse_excgroups():\n  File \"/usr/lib/python3.12/contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/_utils.py\", line 85, in collapse_excgroups\n    raise exc\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 193, in __call__\n    response = await self.dispatch_func(request, call_next)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/api/middleware/request_id.py\", line 58, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 168, in call_next\n    raise app_exc from app_exc.__cause__ or app_exc.__context__\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 191, in __call__\n    with recv_stream, send_stream, collapse_excgroups():\n  File \"/usr/lib/python3.12/contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/_utils.py\", line 85, in collapse_excgroups\n    raise exc\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 193, in __call__\n    response = await self.dispatch_func(request, call_next)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/api/middleware/timing.py\", line 32, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 168, in call_next\n    raise app_exc from app_exc.__cause__ or app_exc.__context__\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 191, in __call__\n    with recv_stream, send_stream, collapse_excgroups():\n  File \"/usr/lib/python3.12/contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/_utils.py\", line 85, in collapse_excgroups\n    raise exc\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 193, in __call__\n    response = await self.dispatch_func(request, call_next)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/core/admin_ops/infrastructure/observability/middleware.py\", line 96, in dispatch\n    raise e\n  File \"/home/daniele/Amber_2.0/src/core/admin_ops/infrastructure/observability/middleware.py\", line 61, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 168, in call_next\n    raise app_exc from app_exc.__cause__ or app_exc.__context__\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 191, in __call__\n    with recv_stream, send_stream, collapse_excgroups():\n  File \"/usr/lib/python3.12/contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/_utils.py\", line 85, in collapse_excgroups\n    raise exc\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 193, in __call__\n    response = await self.dispatch_func(request, call_next)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/api/middleware/rate_limit.py\", line 135, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 168, in call_next\n    raise app_exc from app_exc.__cause__ or app_exc.__context__\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 191, in __call__\n    with recv_stream, send_stream, collapse_excgroups():\n  File \"/usr/lib/python3.12/contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/_utils.py\", line 85, in collapse_excgroups\n    raise exc\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 193, in __call__\n    response = await self.dispatch_func(request, call_next)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/api/middleware/auth.py\", line 232, in dispatch\n    return await call_next(request)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 168, in call_next\n    raise app_exc from app_exc.__cause__ or app_exc.__context__\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 191, in __call__\n    with recv_stream, send_stream, collapse_excgroups():\n  File \"/usr/lib/python3.12/contextlib.py\", line 158, in __exit__\n    self.gen.throw(value)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/_utils.py\", line 85, in collapse_excgroups\n    raise exc\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 193, in __call__\n    response = await self.dispatch_func(request, call_next)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/api/middleware/rate_limit.py\", line 187, in dispatch\n    return await call_next(request)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 168, in call_next\n    raise app_exc from app_exc.__cause__ or app_exc.__context__\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/cors.py\", line 85, in __call__\n    await self.app(scope, receive, send)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/routing.py\", line 716, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/routing.py\", line 736, in app\n    await route.handle(scope, receive, send)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/routing.py\", line 290, in handle\n    await self.app(scope, receive, send)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/fastapi/routing.py\", line 115, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/fastapi/routing.py\", line 101, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/fastapi/routing.py\", line 355, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/fastapi/routing.py\", line 243, in run_endpoint_function\n    return await dependant.call(**values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/api/routes/documents.py\", line 151, in upload_document\n    result = await use_case.execute(\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daniele/Amber_2.0/src/core/ingestion/application/use_cases_documents.py\", line 154, in execute\n    await self._task_dispatcher.dispatch(\n  File \"/home/daniele/Amber_2.0/src/infrastructure/adapters/celery_dispatcher.py\", line 50, in dispatch\n    raise RuntimeError(f\"Task dispatch failed: {e}\") from e\nRuntimeError: Task dispatch failed: Retry in 60s: RuntimeError('Extraction failed after checking 1 tools. Details: {\\'unstructured\\': \\'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install \"unstructured[pdf]\" (including quotes) to install the required dependencies\\'}')"}
------------------------------ Captured log call -------------------------------
INFO     src.core.events.dispatcher:dispatcher.py:44 State Change [Doc: doc_174218dbffc2a138] None -> ingested
INFO     src.core.ingestion.application.ingestion_service:ingestion_service.py:171 Registered new document: test_integration_8e4383ed.pdf (ID: doc_174218dbffc2a138)
INFO     src.workers.tasks:tasks.py:141 [Task d1996ea6-b6f0-4702-b19a-bf1ad6a1aa12] Starting processing for document doc_174218dbffc2a138
INFO     src.workers.tasks:tasks.py:363 Executing deep reset of singletons for background task isolation
INFO     src.workers.tasks:tasks.py:413 Platform registry singletons reset.
INFO     src.core.ingestion.infrastructure.storage.storage_client:storage_client.py:123 DEBUG: MinIO Fetching integration_test_tenant/doc_174218dbffc2a138/test_integration_8e4383ed.pdf from documents
INFO     src.core.ingestion.infrastructure.extraction.fallback:fallback.py:39 Attempting extraction with unstructured for test_integration_8e4383ed.pdf
ERROR    src.core.ingestion.infrastructure.extraction.local.unstructured_extractor:unstructured_extractor.py:86 Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies
WARNING  src.core.ingestion.infrastructure.extraction.fallback:fallback.py:42 Extractor unstructured failed for test_integration_8e4383ed.pdf: Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies
ERROR    src.core.ingestion.infrastructure.extraction.fallback:fallback.py:47 All extractors failed for test_integration_8e4383ed.pdf. Errors: {'unstructured': 'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies'}
ERROR    src.core.ingestion.application.ingestion_service:ingestion_service.py:696 Failed to process document doc_174218dbffc2a138
Traceback (most recent call last):
  File "/home/daniele/Amber_2.0/src/core/ingestion/application/ingestion_service.py", line 233, in process_document
    extraction_result = await extractor.extract(
                        ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/core/ingestion/infrastructure/extraction/fallback_extractor.py", line 9, in extract
    result = await FallbackManager.extract_with_fallback(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/core/ingestion/infrastructure/extraction/fallback.py", line 48, in extract_with_fallback
    raise RuntimeError(
RuntimeError: Extraction failed after checking 1 tools. Details: {'unstructured': 'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies'}
ERROR    src.workers.tasks:tasks.py:161 [Task d1996ea6-b6f0-4702-b19a-bf1ad6a1aa12] Failed processing document doc_174218dbffc2a138: Extraction failed after checking 1 tools. Details: {'unstructured': 'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies'}
Traceback (most recent call last):
  File "/home/daniele/Amber_2.0/src/workers/tasks.py", line 144, in process_document
    result = run_async(_process_document_async(document_id, tenant_id, self.request.id))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/workers/tasks.py", line 76, in run_async
    res = future.result()
          ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/usr/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/workers/tasks.py", line 67, in runner
    res = asyncio.run(coro)
          ^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/base_events.py", line 687, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/workers/tasks.py", line 541, in _process_document_async
    await service.process_document(document_id)
  File "/home/daniele/Amber_2.0/src/core/ingestion/application/ingestion_service.py", line 233, in process_document
    extraction_result = await extractor.extract(
                        ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/core/ingestion/infrastructure/extraction/fallback_extractor.py", line 9, in extract
    result = await FallbackManager.extract_with_fallback(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/core/ingestion/infrastructure/extraction/fallback.py", line 48, in extract_with_fallback
    raise RuntimeError(
RuntimeError: Extraction failed after checking 1 tools. Details: {'unstructured': 'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies'}

ERROR    src.infrastructure.adapters.celery_dispatcher:celery_dispatcher.py:49 Failed to dispatch task src.workers.tasks.process_document: Retry in 60s: RuntimeError('Extraction failed after checking 1 tools. Details: {\'unstructured\': \'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies\'}')
ERROR    src.core.admin_ops.infrastructure.observability.middleware:middleware.py:85 Request exception: Task dispatch failed: Retry in 60s: RuntimeError('Extraction failed after checking 1 tools. Details: {\'unstructured\': \'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies\'}')
ERROR    src.api.middleware.exceptions:exceptions.py:123 Unhandled exception: RuntimeError: Task dispatch failed: Retry in 60s: RuntimeError('Extraction failed after checking 1 tools. Details: {\'unstructured\': \'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies\'}')
Traceback (most recent call last):
  File "/home/daniele/Amber_2.0/src/workers/tasks.py", line 144, in process_document
    result = run_async(_process_document_async(document_id, tenant_id, self.request.id))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/workers/tasks.py", line 76, in run_async
    res = future.result()
          ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/usr/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/workers/tasks.py", line 67, in runner
    res = asyncio.run(coro)
          ^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/base_events.py", line 687, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/workers/tasks.py", line 541, in _process_document_async
    await service.process_document(document_id)
  File "/home/daniele/Amber_2.0/src/core/ingestion/application/ingestion_service.py", line 233, in process_document
    extraction_result = await extractor.extract(
                        ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/core/ingestion/infrastructure/extraction/fallback_extractor.py", line 9, in extract
    result = await FallbackManager.extract_with_fallback(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/core/ingestion/infrastructure/extraction/fallback.py", line 48, in extract_with_fallback
    raise RuntimeError(
RuntimeError: Extraction failed after checking 1 tools. Details: {'unstructured': 'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/daniele/Amber_2.0/src/infrastructure/adapters/celery_dispatcher.py", line 39, in dispatch
    result = task.apply(args=args, kwargs=kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/celery/app/task.py", line 843, in apply
    ret = tracer(task_id, args, kwargs, request)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/celery/app/trace.py", line 494, in trace_task
    I, R, state, retval = on_error(
                          ^^^^^^^^^
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/celery/app/trace.py", line 479, in trace_task
    R = retval = fun(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/celery/app/autoretry.py", line 38, in run
    return task._orig_run(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/workers/tasks.py", line 173, in process_document
    raise self.retry(exc=e)
          ^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/celery/app/task.py", line 763, in retry
    raise ret
celery.exceptions.Retry: Retry in 60s: RuntimeError('Extraction failed after checking 1 tools. Details: {\'unstructured\': \'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies\'}')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 191, in __call__
    with recv_stream, send_stream, collapse_excgroups():
  File "/usr/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/_utils.py", line 85, in collapse_excgroups
    raise exc
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 193, in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/api/middleware/request_id.py", line 58, in dispatch
    response = await call_next(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 168, in call_next
    raise app_exc from app_exc.__cause__ or app_exc.__context__
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 144, in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 191, in __call__
    with recv_stream, send_stream, collapse_excgroups():
  File "/usr/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/_utils.py", line 85, in collapse_excgroups
    raise exc
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 193, in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/api/middleware/timing.py", line 32, in dispatch
    response = await call_next(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 168, in call_next
    raise app_exc from app_exc.__cause__ or app_exc.__context__
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 144, in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 191, in __call__
    with recv_stream, send_stream, collapse_excgroups():
  File "/usr/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/_utils.py", line 85, in collapse_excgroups
    raise exc
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 193, in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/core/admin_ops/infrastructure/observability/middleware.py", line 96, in dispatch
    raise e
  File "/home/daniele/Amber_2.0/src/core/admin_ops/infrastructure/observability/middleware.py", line 61, in dispatch
    response = await call_next(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 168, in call_next
    raise app_exc from app_exc.__cause__ or app_exc.__context__
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 144, in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 191, in __call__
    with recv_stream, send_stream, collapse_excgroups():
  File "/usr/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/_utils.py", line 85, in collapse_excgroups
    raise exc
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 193, in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/api/middleware/rate_limit.py", line 135, in dispatch
    response = await call_next(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 168, in call_next
    raise app_exc from app_exc.__cause__ or app_exc.__context__
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 144, in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 191, in __call__
    with recv_stream, send_stream, collapse_excgroups():
  File "/usr/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/_utils.py", line 85, in collapse_excgroups
    raise exc
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 193, in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/api/middleware/auth.py", line 232, in dispatch
    return await call_next(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 168, in call_next
    raise app_exc from app_exc.__cause__ or app_exc.__context__
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 144, in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 191, in __call__
    with recv_stream, send_stream, collapse_excgroups():
  File "/usr/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/_utils.py", line 85, in collapse_excgroups
    raise exc
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 193, in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/api/middleware/rate_limit.py", line 187, in dispatch
    return await call_next(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 168, in call_next
    raise app_exc from app_exc.__cause__ or app_exc.__context__
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 144, in coro
    await self.app(scope, receive_or_disconnect, send_no_error)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/cors.py", line 85, in __call__
    await self.app(scope, receive, send)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 63, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/fastapi/middleware/asyncexitstack.py", line 18, in __call__
    await self.app(scope, receive, send)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/routing.py", line 716, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/routing.py", line 736, in app
    await route.handle(scope, receive, send)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/routing.py", line 290, in handle
    await self.app(scope, receive, send)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/fastapi/routing.py", line 115, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/fastapi/routing.py", line 101, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/fastapi/routing.py", line 355, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/.venv/lib/python3.12/site-packages/fastapi/routing.py", line 243, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/api/routes/documents.py", line 151, in upload_document
    result = await use_case.execute(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/daniele/Amber_2.0/src/core/ingestion/application/use_cases_documents.py", line 154, in execute
    await self._task_dispatcher.dispatch(
  File "/home/daniele/Amber_2.0/src/infrastructure/adapters/celery_dispatcher.py", line 50, in dispatch
    raise RuntimeError(f"Task dispatch failed: {e}") from e
RuntimeError: Task dispatch failed: Retry in 60s: RuntimeError('Extraction failed after checking 1 tools. Details: {\'unstructured\': \'Unstructured extraction failed: partition_pdf() is not available because one or more dependencies are not installed. Use: pip install "unstructured[pdf]" (including quotes) to install the required dependencies\'}')
--------------------------- Captured stdout teardown ---------------------------
{"timestamp": "2026-02-13 18:18:52,899", "level": "INFO", "message": "Connected to Neo4j at bolt://localhost:7687", "module": "neo4j_client", "function": "connect", "line": 55}
{"timestamp": "2026-02-13 18:18:53,745", "level": "INFO", "message": "Connected to Milvus at localhost:19530", "module": "milvus", "function": "connect", "line": 158}
{"timestamp": "2026-02-13 18:18:58,627", "level": "INFO", "message": "Deleted 0 chunks for tenant integration_test_tenant", "module": "milvus", "function": "delete_by_tenant", "line": 599}
{"timestamp": "2026-02-13 18:18:58,630", "level": "INFO", "message": "Creating collection: amber_integration_test_tenant", "module": "milvus", "function": "_create_collection", "line": 169}
{"timestamp": "2026-02-13 18:19:01,129", "level": "INFO", "message": "Collection amber_integration_test_tenant created with HNSW index and Dynamic Fields", "module": "milvus", "function": "_create_collection", "line": 259}
{"timestamp": "2026-02-13 18:19:01,129", "level": "INFO", "message": "Connected to Milvus at localhost:19530", "module": "milvus", "function": "connect", "line": 158}
{"timestamp": "2026-02-13 18:19:01,133", "level": "WARNING", "message": "Dropped collection amber_integration_test_tenant", "module": "milvus", "function": "drop_collection", "line": 798}
---------------------------- Captured log teardown -----------------------------
INFO     src.core.graph.infrastructure.neo4j_client:neo4j_client.py:55 Connected to Neo4j at bolt://localhost:7687
INFO     src.core.retrieval.infrastructure.vector_store.milvus:milvus.py:158 Connected to Milvus at localhost:19530
INFO     src.core.retrieval.infrastructure.vector_store.milvus:milvus.py:599 Deleted 0 chunks for tenant integration_test_tenant
INFO     src.core.retrieval.infrastructure.vector_store.milvus:milvus.py:169 Creating collection: amber_integration_test_tenant
INFO     src.core.retrieval.infrastructure.vector_store.milvus:milvus.py:259 Collection amber_integration_test_tenant created with HNSW index and Dynamic Fields
INFO     src.core.retrieval.infrastructure.vector_store.milvus:milvus.py:158 Connected to Milvus at localhost:19530
WARNING  src.core.retrieval.infrastructure.vector_store.milvus:milvus.py:798 Dropped collection amber_integration_test_tenant
=========================== short test summary info ============================
FAILED tests/integration/test_ingestion_pipeline.py::TestIngestionPipeline::test_complete_pipeline
============================== 1 failed in 15.30s ==============================
